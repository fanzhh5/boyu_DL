{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_j7o1a6n",
    "id": "69262AB48D5C40E0893D46893CFE9B60",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## course content\n",
    "\n",
    "1. lenet 模型介绍\n",
    "2. lenet 网络搭建\n",
    "3. 运用lenet进行图像识别-fashion-mnist数据集\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "graffitiCellId": "id_ajekwu7",
    "id": "Z4Mfv4K6dbhQ",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#  Convolutional Neural Networks\n",
    "\n",
    "使用全连接层的局限性：\n",
    "\n",
    "- 图像在同一列邻近的像素在这个向量中可能相距较远。它们构成的模式可能难以被模型识别。\n",
    "- 对于大尺寸的输入图像，使用全连接层容易导致模型过大。\n",
    "\n",
    "使用卷积层的优势：\n",
    "\n",
    "- 卷积层保留输入形状。\n",
    "- 卷积层通过滑动窗口将同一卷积核与不同位置的输入重复计算，从而避免参数尺寸过大。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_kpncnr4",
    "id": "DCCD52CB4C38495789BA2C76F01D4332",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## LeNet 模型\n",
    "\n",
    "LeNet分为卷积层块和全连接层块两个部分。下面我们分别介绍这两个模块。\n",
    "\n",
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/image/q5ndwsmsao.png?imageView2/0/w/960/h/960)\n",
    "\n",
    "\n",
    "卷积层块里的基本单位是卷积层后接平均池化层：卷积层用来识别图像里的空间模式，如线条和物体局部，之后的平均池化层则用来降低卷积层对位置的敏感性。\n",
    "\n",
    "卷积层块由两个这样的基本单位重复堆叠构成。在卷积层块中，每个卷积层都使用$5 \\times 5$的窗口，并在输出上使用sigmoid激活函数。第一个卷积层输出通道数为6，第二个卷积层输出通道数则增加到16。\n",
    "\n",
    "全连接层块含3个全连接层。它们的输出个数分别是120、84和10，其中10为输出的类别个数。\n",
    "\n",
    "下面我们通过Sequential类来实现LeNet模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "graffitiCellId": "id_r0mf24i",
    "id": "DHAr1_2J1jMC",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #import\n",
    "# import sys\n",
    "# sys.path.append(\"/home/kesci/input\")\n",
    "# import d2lzh1981 as d2l\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "graffitiCellId": "id_jxhddby",
    "id": "hp3vLYIbdbhd",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#net\n",
    "class Flatten(torch.nn.Module):  #展平操作\n",
    "    def forward(self, x):\n",
    "        return x.view(x.shape[0], -1)\n",
    "\n",
    "class Reshape(torch.nn.Module): #将图像大小重定型\n",
    "    def forward(self, x):\n",
    "        return x.view(-1,1,28,28)      #(B x C x H x W)\n",
    "    \n",
    "net = torch.nn.Sequential(     #Lelet                                                  \n",
    "    Reshape(),\n",
    "    nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2), #b*1*28*28  =>b*6*28*28\n",
    "    nn.Sigmoid(),                                                       \n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),                              #b*6*28*28  =>b*6*14*14\n",
    "    nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),           #b*6*14*14  =>b*16*10*10\n",
    "    nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),                              #b*16*10*10  => b*16*5*5\n",
    "    Flatten(),                                                          #b*16*5*5   => b*400\n",
    "    nn.Linear(in_features=16*5*5, out_features=120),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(120, 84),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(84, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "graffitiCellId": "id_00eauaf",
    "id": "OnaREs_Zdbhg",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "接下来我们构造一个高和宽均为28的单通道数据样本，并逐层进行前向计算来查看每个层的输出形状。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "graffitiCellId": "id_l3of2c4",
    "id": "yiamwgtvdbhh",
    "jupyter": {},
    "outputId": "88be586b-b793-48b7-f4e2-7e598cecd22e",
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshape output shape: \t torch.Size([1, 1, 28, 28])\n",
      "Conv2d output shape: \t torch.Size([1, 6, 28, 28])\n",
      "Sigmoid output shape: \t torch.Size([1, 6, 28, 28])\n",
      "AvgPool2d output shape: \t torch.Size([1, 6, 14, 14])\n",
      "Conv2d output shape: \t torch.Size([1, 16, 10, 10])\n",
      "Sigmoid output shape: \t torch.Size([1, 16, 10, 10])\n",
      "AvgPool2d output shape: \t torch.Size([1, 16, 5, 5])\n",
      "Flatten output shape: \t torch.Size([1, 400])\n",
      "Linear output shape: \t torch.Size([1, 120])\n",
      "Sigmoid output shape: \t torch.Size([1, 120])\n",
      "Linear output shape: \t torch.Size([1, 84])\n",
      "Sigmoid output shape: \t torch.Size([1, 84])\n",
      "Linear output shape: \t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "#print\n",
    "X = torch.randn(size=(1,1,28,28), dtype = torch.float32)\n",
    "for layer in net:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__,'output shape: \\t',X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "graffitiCellId": "id_0ppp3nj",
    "id": "fzicoTnEdbhl",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "可以看到，在卷积层块中输入的高和宽在逐层减小。卷积层由于使用高和宽均为5的卷积核，从而将高和宽分别减小4，而池化层则将高和宽减半，但通道数则从1增加到16。全连接层则逐层减少输出个数，直到变成图像的类别数10。\n",
    "\n",
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/image/q5ndxi6jl5.png?imageView2/0/w/640/h/640)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "graffitiCellId": "id_p1kzp1a",
    "id": "BnKUIw6Ddbhr",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 获取数据和训练模型\n",
    "\n",
    "下面我们来实现LeNet模型。我们仍然使用Fashion-MNIST作为训练数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用这个链接的教程将urls改为本地文件夹\n",
    "# https://blog.csdn.net/york1996/article/details/81780065?utm_source=distribute.pc_relevant.none-task\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "batch_size = 256\n",
    "num_workers = 4\n",
    "PATH = 'C:/jupyter_notebook/boyu/datasets/FashionMNIST2065'\n",
    "mnist_train = torchvision.datasets.FashionMNIST(root=PATH, train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_test = torchvision.datasets.FashionMNIST(root=PATH, train=False, download=True, transform=transforms.ToTensor())\n",
    "train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "graffitiCellId": "id_f0dgnij",
    "id": "ECMwOKTzdbhr",
    "jupyter": {},
    "outputId": "9a7f2ac9-c95b-4bbb-e902-dcfbfd16301a",
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235\n"
     ]
    }
   ],
   "source": [
    "# # 数据\n",
    "# batch_size = 256\n",
    "# train_iter, test_iter = d2l.load_data_fashion_mnist(\n",
    "#     batch_size=batch_size, root='/home/kesci/input/FashionMNIST2065')\n",
    "print(len(train_iter))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_uge3tcz",
    "id": "D38DDA51EF0D4AFE809003A1686CDA11",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "为了使读者更加形象的看到数据，添加额外的部分来展示数据的图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "graffitiCellId": "id_d5nld6i",
    "id": "4FE5CE6E20494BFE898E9D8EAAF30C7B",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28]) 1\n",
      "torch.Size([1, 28, 28]) 0\n",
      "torch.Size([1, 28, 28]) 3\n",
      "torch.Size([1, 28, 28]) 1\n",
      "torch.Size([1, 28, 28]) 0\n",
      "torch.Size([1, 28, 28]) 2\n",
      "torch.Size([1, 28, 28]) 8\n",
      "torch.Size([1, 28, 28]) 2\n",
      "torch.Size([1, 28, 28]) 9\n",
      "torch.Size([1, 28, 28]) 9\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n",
       "<svg height=\"86.263888pt\" version=\"1.1\" viewBox=\"0 0 684 86.263888\" width=\"684pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       " <defs>\r\n",
       "  <style type=\"text/css\">\r\n",
       "*{stroke-linecap:butt;stroke-linejoin:round;}\r\n",
       "  </style>\r\n",
       " </defs>\r\n",
       " <g id=\"figure_1\">\r\n",
       "  <g id=\"patch_1\">\r\n",
       "   <path d=\"M 0 86.263888 \r\n",
       "L 684 86.263888 \r\n",
       "L 684 -0 \r\n",
       "L 0 -0 \r\n",
       "z\r\n",
       "\" style=\"fill:#ffffff;\"/>\r\n",
       "  </g>\r\n",
       "  <g id=\"axes_1\">\r\n",
       "   <g id=\"patch_2\">\r\n",
       "    <path d=\"M 7.2 79.063888 \r\n",
       "L 63.945763 79.063888 \r\n",
       "L 63.945763 22.318125 \r\n",
       "L 7.2 22.318125 \r\n",
       "z\r\n",
       "\" style=\"fill:#ffffff;\"/>\r\n",
       "   </g>\r\n",
       "   <g clip-path=\"url(#pde24ffd412)\">\r\n",
       "    <image height=\"56.88\" id=\"image77d5e6aa86\" transform=\"scale(1 -1)translate(0 -56.88)\" width=\"56.88\" x=\"7.2\" xlink:href=\"data:image/png;base64,\r\n",
       "iVBORw0KGgoAAAANSUhEUgAAAE8AAABPCAYAAACqNJiGAAAABHNCSVQICAgIfAhkiAAABS9JREFUeJztnM9vG0UUx8cer9e/fyR20qY/aENaKIiGE6AK0UsPiHMlEBdu3BD/BZf+DREHTnDMAQkJegUOlUAC9RDyozJt0yRN4jpZr/cnh23eeyaunfLsUYTe5/TVaHc9fvu+OzM7M5u6lbodK4PENxZBf7z0A+ivH9wAXfxwbeg1Nr69Dvqbd5ZAf7L8BegrX/7CqudJSE/8F/7HSPAYZEz/4F+f5kDfLq+Ddi9aoJdTjUTEg58on137FbQfa9A33/0T9CN2TUcjmcdAgsfAuG0zjS7on90a6A23gQe9wK5HrDgzoOftLdBhnBpDDU+OZB4D45n39vmHoJ9F2HhEfVkzPPNohoXk/ue1z6/gSyCZx0CCx8C4befybdCa2LPfcloNw06HoA8jG/SF3B7oDZVTk0Yyj4EEj4Fx25Z0DzQdWr0M6VQEuhfhsK6eOSRHiW1PNRI8BsZtS3FjtFwvolUZ3kmm1ndjPK+pO2Or20mQzGMgwWNg3LZl7YLuhHnTPz9WJPMYSPAYGLdtJ8TOK+3sFrSH5YWqUkqpyHEGXsNOB6B90kqHsdlckMxjYDzznvQqoGnjUUiTzKsmx7wo8+oWDsO2PLxeLzb7dyTzGEjwGBi3bZ40DPQBTy0cvPJ8duzxJpTpWZwxm9JYvhlXQc9Yz8gvTY+jukORzGMgwWNg3LaLxRboxz5OetO3I87ZZNhWIOdFF2cHXo9OPX5UvA96Wb3PrepIJPMYSPAYGLdtTWPHd9XFFtRK4XRidyq5p9S2e6+XQGsyrNv18Kg2mc8wgWQeAwkeA+O2DRUu0jkIcbZ/JosdXOdMcgzt5h6cH718jF7bBJJ5DCR4DIzbNpfCBT10urGvtZ331L9xFgaPiZ0gC7qcxmvrK/PJsSvD93RwkMxjYDzzsiTDPJJ57QD7a7XGwbHzFi49Ae2QZWWUbTIbF04/7xeu/OeqjkQyj4EEj4Fx29L1JG0PZ9KqFRy2vdlMXnZuk/NuNtF/NmkYqPXp2he3kVx7kgvNJPMYSPAYmLHte7g/VivcdBeQlaFr3SboxUrywvRHVYayBRtb23uHl0Dvu9jC0sXdXiXJC7HtKUWCx8CIbXffKII+JC0itVxL10HP55N2NnNuDsrmrN9Af997C7SdwXUrmwGZE6kleYHrCcaPZB4DCR4DI7Z1ZvEl5cMA7emFg/dhbPmJ2bzLOMexH+LYl75JsXVw7DyllKLbdyeFZB4DI5kXlHBrAH0jkrdwmNXuYeNxX51RSim1+jne2z+6F0B3yLAuIO/2dnycYfPLk/9cjGQeAwkeAyO2DfH53vfg90mDUbfxrcpCMennfXfrJyi7s/sqHpvDY7e7aNW+3yyHA8vHiWQeAwkeAyO2jTOktSUT3ZYebK2nfjKc+2rnNSjbI3McU1m07VMXh359ZKPB5WNEMo+BBI+BEdvaO3iPCmSvbDqFdi5ZWH60n3a9i2Ms2hmmcx9psjd3xsL5EbtFmvgJIZnHQILHwIhtq+vY8jUzaC36/Sg3xJekrW79WFmOfLSm46Ntuz4eQ/dyVNZkbHuqkeAxMGLb+u/4jadpjYt46HiW2vLIrhULbegEaM9rVdw+9aiL26fo/t1y6/gytXEjmcfAzPBs9QHoKZJ50yTzrpf+Bn20FuVqFjNsw8c+n0d2C52z90FHpC+YuXuPW+2RSOYxkOAxMGLbyMUH/9L2B6DXOrhZ4O7KVTxhJ3nzYrXx3no1bAxiG3V9Dj9mGER4/FmFm/gmhWQeAwkeg38AUrNn3sEJsR4AAAAASUVORK5CYII=\" y=\"-22.183888\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_3\">\r\n",
       "    <path d=\"M 7.2 79.063888 \r\n",
       "L 7.2 22.318125 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_4\">\r\n",
       "    <path d=\"M 63.945763 79.063888 \r\n",
       "L 63.945763 22.318125 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_5\">\r\n",
       "    <path d=\"M 7.2 79.063888 \r\n",
       "L 63.945763 79.063888 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_6\">\r\n",
       "    <path d=\"M 7.2 22.318125 \r\n",
       "L 63.945763 22.318125 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"text_1\">\r\n",
       "    <!-- 1 -->\r\n",
       "    <defs>\r\n",
       "     <path d=\"M 12.40625 8.296875 \r\n",
       "L 28.515625 8.296875 \r\n",
       "L 28.515625 63.921875 \r\n",
       "L 10.984375 60.40625 \r\n",
       "L 10.984375 69.390625 \r\n",
       "L 28.421875 72.90625 \r\n",
       "L 38.28125 72.90625 \r\n",
       "L 38.28125 8.296875 \r\n",
       "L 54.390625 8.296875 \r\n",
       "L 54.390625 0 \r\n",
       "L 12.40625 0 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-49\"/>\r\n",
       "    </defs>\r\n",
       "    <g transform=\"translate(31.755381 16.318125)scale(0.12 -0.12)\">\r\n",
       "     <use xlink:href=\"#DejaVuSans-49\"/>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "  </g>\r\n",
       "  <g id=\"axes_2\">\r\n",
       "   <g id=\"patch_7\">\r\n",
       "    <path d=\"M 75.294915 79.063888 \r\n",
       "L 132.040678 79.063888 \r\n",
       "L 132.040678 22.318125 \r\n",
       "L 75.294915 22.318125 \r\n",
       "z\r\n",
       "\" style=\"fill:#ffffff;\"/>\r\n",
       "   </g>\r\n",
       "   <g clip-path=\"url(#p7d57ef0d92)\">\r\n",
       "    <image height=\"56.88\" id=\"image007b66864b\" transform=\"scale(1 -1)translate(0 -56.88)\" width=\"56.88\" x=\"75.294915\" xlink:href=\"data:image/png;base64,\r\n",
       "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\" y=\"-22.183888\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_8\">\r\n",
       "    <path d=\"M 75.294915 79.063888 \r\n",
       "L 75.294915 22.318125 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_9\">\r\n",
       "    <path d=\"M 132.040678 79.063888 \r\n",
       "L 132.040678 22.318125 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_10\">\r\n",
       "    <path d=\"M 75.294915 79.063888 \r\n",
       "L 132.040678 79.063888 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_11\">\r\n",
       "    <path d=\"M 75.294915 22.318125 \r\n",
       "L 132.040678 22.318125 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"text_2\">\r\n",
       "    <!-- 0 -->\r\n",
       "    <defs>\r\n",
       "     <path d=\"M 31.78125 66.40625 \r\n",
       "Q 24.171875 66.40625 20.328125 58.90625 \r\n",
       "Q 16.5 51.421875 16.5 36.375 \r\n",
       "Q 16.5 21.390625 20.328125 13.890625 \r\n",
       "Q 24.171875 6.390625 31.78125 6.390625 \r\n",
       "Q 39.453125 6.390625 43.28125 13.890625 \r\n",
       "Q 47.125 21.390625 47.125 36.375 \r\n",
       "Q 47.125 51.421875 43.28125 58.90625 \r\n",
       "Q 39.453125 66.40625 31.78125 66.40625 \r\n",
       "z\r\n",
       "M 31.78125 74.21875 \r\n",
       "Q 44.046875 74.21875 50.515625 64.515625 \r\n",
       "Q 56.984375 54.828125 56.984375 36.375 \r\n",
       "Q 56.984375 17.96875 50.515625 8.265625 \r\n",
       "Q 44.046875 -1.421875 31.78125 -1.421875 \r\n",
       "Q 19.53125 -1.421875 13.0625 8.265625 \r\n",
       "Q 6.59375 17.96875 6.59375 36.375 \r\n",
       "Q 6.59375 54.828125 13.0625 64.515625 \r\n",
       "Q 19.53125 74.21875 31.78125 74.21875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-48\"/>\r\n",
       "    </defs>\r\n",
       "    <g transform=\"translate(99.850297 16.318125)scale(0.12 -0.12)\">\r\n",
       "     <use xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "  </g>\r\n",
       "  <g id=\"axes_3\">\r\n",
       "   <g id=\"patch_12\">\r\n",
       "    <path d=\"M 143.389831 79.063888 \r\n",
       "L 200.135593 79.063888 \r\n",
       "L 200.135593 22.318125 \r\n",
       "L 143.389831 22.318125 \r\n",
       "z\r\n",
       "\" style=\"fill:#ffffff;\"/>\r\n",
       "   </g>\r\n",
       "   <g clip-path=\"url(#p077252f8a2)\">\r\n",
       "    <image height=\"56.88\" id=\"image94c04463ea\" transform=\"scale(1 -1)translate(0 -56.88)\" width=\"56.88\" x=\"143.389831\" xlink:href=\"data:image/png;base64,\r\n",
       "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\" y=\"-22.183888\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_13\">\r\n",
       "    <path d=\"M 143.389831 79.063888 \r\n",
       "L 143.389831 22.318125 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_14\">\r\n",
       "    <path d=\"M 200.135593 79.063888 \r\n",
       "L 200.135593 22.318125 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_15\">\r\n",
       "    <path d=\"M 143.389831 79.063888 \r\n",
       "L 200.135593 79.063888 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_16\">\r\n",
       "    <path d=\"M 143.389831 22.318125 \r\n",
       "L 200.135593 22.318125 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"text_3\">\r\n",
       "    <!-- 3 -->\r\n",
       "    <defs>\r\n",
       "     <path d=\"M 40.578125 39.3125 \r\n",
       "Q 47.65625 37.796875 51.625 33 \r\n",
       "Q 55.609375 28.21875 55.609375 21.1875 \r\n",
       "Q 55.609375 10.40625 48.1875 4.484375 \r\n",
       "Q 40.765625 -1.421875 27.09375 -1.421875 \r\n",
       "Q 22.515625 -1.421875 17.65625 -0.515625 \r\n",
       "Q 12.796875 0.390625 7.625 2.203125 \r\n",
       "L 7.625 11.71875 \r\n",
       "Q 11.71875 9.328125 16.59375 8.109375 \r\n",
       "Q 21.484375 6.890625 26.8125 6.890625 \r\n",
       "Q 36.078125 6.890625 40.9375 10.546875 \r\n",
       "Q 45.796875 14.203125 45.796875 21.1875 \r\n",
       "Q 45.796875 27.640625 41.28125 31.265625 \r\n",
       "Q 36.765625 34.90625 28.71875 34.90625 \r\n",
       "L 20.21875 34.90625 \r\n",
       "L 20.21875 43.015625 \r\n",
       "L 29.109375 43.015625 \r\n",
       "Q 36.375 43.015625 40.234375 45.921875 \r\n",
       "Q 44.09375 48.828125 44.09375 54.296875 \r\n",
       "Q 44.09375 59.90625 40.109375 62.90625 \r\n",
       "Q 36.140625 65.921875 28.71875 65.921875 \r\n",
       "Q 24.65625 65.921875 20.015625 65.03125 \r\n",
       "Q 15.375 64.15625 9.8125 62.3125 \r\n",
       "L 9.8125 71.09375 \r\n",
       "Q 15.4375 72.65625 20.34375 73.4375 \r\n",
       "Q 25.25 74.21875 29.59375 74.21875 \r\n",
       "Q 40.828125 74.21875 47.359375 69.109375 \r\n",
       "Q 53.90625 64.015625 53.90625 55.328125 \r\n",
       "Q 53.90625 49.265625 50.4375 45.09375 \r\n",
       "Q 46.96875 40.921875 40.578125 39.3125 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-51\"/>\r\n",
       "    </defs>\r\n",
       "    <g transform=\"translate(167.945212 16.318125)scale(0.12 -0.12)\">\r\n",
       "     <use xlink:href=\"#DejaVuSans-51\"/>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "  </g>\r\n",
       "  <g id=\"axes_4\">\r\n",
       "   <g id=\"patch_17\">\r\n",
       "    <path d=\"M 211.484746 79.063888 \r\n",
       "L 268.230508 79.063888 \r\n",
       "L 268.230508 22.318125 \r\n",
       "L 211.484746 22.318125 \r\n",
       "z\r\n",
       "\" style=\"fill:#ffffff;\"/>\r\n",
       "   </g>\r\n",
       "   <g clip-path=\"url(#p099dadf759)\">\r\n",
       "    <image height=\"56.88\" id=\"imagecac8930717\" transform=\"scale(1 -1)translate(0 -56.88)\" width=\"56.88\" x=\"211.484746\" xlink:href=\"data:image/png;base64,\r\n",
       "iVBORw0KGgoAAAANSUhEUgAAAE8AAABPCAYAAACqNJiGAAAABHNCSVQICAgIfAhkiAAABLpJREFUeJztXM9vG0UUntkftpM4seu0TigCVWrppaAiCqgClQNCPXDggBB3Tvwh/BMg9Z4jhx6QyrlcCoKKVmrpBVC54CYN8Y/EuzuzHKLM9yLWbpxXPzXofadP9uzu+O37/N7MvBn7kf2sNIJYvX0q8HOLm4Fv/PJO4Be/+Ok/1/124+3AP7/yY+W9775bC7zMM1Y/j4Jo7k/4H0ONx0Ai8ZDyvcuBX1/9LvA9nwb+4PrXgX9iIOEDbHz4TeA/jF4LPLI+8LtvXsMFd349foePCPU8BtR4DIjI1pB43iuWA2/YIvB72fSgv+mXAu+7Bu4R5WhUeCMJ9TwGRDwvyl3gsan2sLPx9LxsNRoG7o3FvUnAkHYF9TwG1HgMyASMCRh5DKc6cX1qW0ekmlr8DeQeP8GSvweJMad6HgNqPAZkZOsgoryMn+utqfSjwV7gEhmfeh4DajwGRGQbP+0HTmdSTqf4fMuNp96j51YCp9KnvNzpG0mo5zGgxmNAJtrmmD2hMvMl3l3PT+/K0COJptL3pa1qLgL1PAbUeAzIyNYjZaUyOxw1j/4e6T0OybYoKlrPD+p5DMisnrUx9T4mgWGWoZojHjaeEFxsC7mg2f5nhh4eD+p5DKjxGBCRbdHBylcSIXjQfK0dTV/DaMejwKls6xGChOsQ2f5xrK7OBPU8BtR4DMhEW5KK0bxs4DDkWound+V8inK0jMh2Icait2+Q9Yxj9XQ2qOcxoMZjQEa2Cd7RteWHgd/afiPw1E5PmFNSGTB26PanXVSJ3q/hfirbFxxqPAZkkuQlSHJEJjUnjVGrQMe2foIofQxfkPAK9TwG1HgMiMg2J7KlRTq7DmPbqOo9RrhunQTjwqNtTGoDXAOfS/ww9TwGZAJGg5aHYRbkWStf8Uoz8Lp9dlep50lAPY8BNR4DMgFjEZzmeRRVwzO7jLWP2FavmOUlfkLWhC+QR84N6nkMqPEYEJGtq0NmGVluTCJX1dzY+r60y8VG5fd0HYQWemdN2boV9TwG1HgMyCTJJPTFFsXdfkJ9SvzyS8YYY4YXsKV+r0RyHZF70OFe1mJ3dSao5zGgxmNARrZNyIxOau7kiKZ5CfltXV03xhiz+Tra3suQXI8K7L3YdvhP2OvqftsTA5k8r0F3AOGRNVJnstFfC/zMl78bY4x5hSxo3+pjZayZYNsBHe75ZS1uPDFQ4zEgIltPZOvI+2ql2Gh3ewdnpXx8Zv9MlMdZJ3z2eBc5X6eGcjO6xWDx1O5z6vHRoJ7HgBqPAZmtBE1SBnZoIhPvbsGizc+DV40xh4dy7XRErquua0lizfNODNR4DMjIlsxRdpJB4PUJk6HtdD9qUonT2RNHFr3pUib9XALqeQyo8RgQkW36JxLZ7vvYyj72iJoL5CypUH9iq99tQa5bT7BNavj3UlXzuUE9jwE1HgMism09AqdHtg1yyPkgwhqD8S8tH6OHz2znC4F3Y0TvlYeyR2Op5zEg8qpOf3s/8HNfwVMut/4KnNYnH/Ax6R7N884v9QK/VEObs99vBa7HIb3gUOMxYKXPhn9y82Lgb3Uh27X6TuCdZP98UDdhy8DTHPncA7L2MfygV9V8blDPY0CNx8C/YfNJn2f6vaQAAAAASUVORK5CYII=\" y=\"-22.183888\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_18\">\r\n",
       "    <path d=\"M 211.484746 79.063888 \r\n",
       "L 211.484746 22.318125 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_19\">\r\n",
       "    <path d=\"M 268.230508 79.063888 \r\n",
       "L 268.230508 22.318125 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_20\">\r\n",
       "    <path d=\"M 211.484746 79.063888 \r\n",
       "L 268.230508 79.063888 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_21\">\r\n",
       "    <path d=\"M 211.484746 22.318125 \r\n",
       "L 268.230508 22.318125 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"text_4\">\r\n",
       "    <!-- 1 -->\r\n",
       "    <g transform=\"translate(236.040127 16.318125)scale(0.12 -0.12)\">\r\n",
       "     <use xlink:href=\"#DejaVuSans-49\"/>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "  </g>\r\n",
       "  <g id=\"axes_5\">\r\n",
       "   <g id=\"patch_22\">\r\n",
       "    <path d=\"M 279.579661 79.063888 \r\n",
       "L 336.325424 79.063888 \r\n",
       "L 336.325424 22.318125 \r\n",
       "L 279.579661 22.318125 \r\n",
       "z\r\n",
       "\" style=\"fill:#ffffff;\"/>\r\n",
       "   </g>\r\n",
       "   <g clip-path=\"url(#p37d34cf62d)\">\r\n",
       "    <image height=\"56.88\" id=\"image780c752447\" transform=\"scale(1 -1)translate(0 -56.88)\" width=\"56.88\" x=\"279.579661\" xlink:href=\"data:image/png;base64,\r\n",
       "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\" y=\"-22.183888\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_23\">\r\n",
       "    <path d=\"M 279.579661 79.063888 \r\n",
       "L 279.579661 22.318125 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_24\">\r\n",
       "    <path d=\"M 336.325424 79.063888 \r\n",
       "L 336.325424 22.318125 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_25\">\r\n",
       "    <path d=\"M 279.579661 79.063888 \r\n",
       "L 336.325424 79.063888 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_26\">\r\n",
       "    <path d=\"M 279.579661 22.318125 \r\n",
       "L 336.325424 22.318125 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"text_5\">\r\n",
       "    <!-- 0 -->\r\n",
       "    <g transform=\"translate(304.135042 16.318125)scale(0.12 -0.12)\">\r\n",
       "     <use xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "  </g>\r\n",
       "  <g id=\"axes_6\">\r\n",
       "   <g id=\"patch_27\">\r\n",
       "    <path d=\"M 347.674576 79.063888 \r\n",
       "L 404.420339 79.063888 \r\n",
       "L 404.420339 22.318125 \r\n",
       "L 347.674576 22.318125 \r\n",
       "z\r\n",
       "\" style=\"fill:#ffffff;\"/>\r\n",
       "   </g>\r\n",
       "   <g clip-path=\"url(#pe4ddc55660)\">\r\n",
       "    <image height=\"56.88\" id=\"image8070377538\" transform=\"scale(1 -1)translate(0 -56.88)\" width=\"56.88\" x=\"347.674576\" xlink:href=\"data:image/png;base64,\r\n",
       "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\" y=\"-22.183888\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_28\">\r\n",
       "    <path d=\"M 347.674576 79.063888 \r\n",
       "L 347.674576 22.318125 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_29\">\r\n",
       "    <path d=\"M 404.420339 79.063888 \r\n",
       "L 404.420339 22.318125 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_30\">\r\n",
       "    <path d=\"M 347.674576 79.063888 \r\n",
       "L 404.420339 79.063888 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_31\">\r\n",
       "    <path d=\"M 347.674576 22.318125 \r\n",
       "L 404.420339 22.318125 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"text_6\">\r\n",
       "    <!-- 2 -->\r\n",
       "    <defs>\r\n",
       "     <path d=\"M 19.1875 8.296875 \r\n",
       "L 53.609375 8.296875 \r\n",
       "L 53.609375 0 \r\n",
       "L 7.328125 0 \r\n",
       "L 7.328125 8.296875 \r\n",
       "Q 12.9375 14.109375 22.625 23.890625 \r\n",
       "Q 32.328125 33.6875 34.8125 36.53125 \r\n",
       "Q 39.546875 41.84375 41.421875 45.53125 \r\n",
       "Q 43.3125 49.21875 43.3125 52.78125 \r\n",
       "Q 43.3125 58.59375 39.234375 62.25 \r\n",
       "Q 35.15625 65.921875 28.609375 65.921875 \r\n",
       "Q 23.96875 65.921875 18.8125 64.3125 \r\n",
       "Q 13.671875 62.703125 7.8125 59.421875 \r\n",
       "L 7.8125 69.390625 \r\n",
       "Q 13.765625 71.78125 18.9375 73 \r\n",
       "Q 24.125 74.21875 28.421875 74.21875 \r\n",
       "Q 39.75 74.21875 46.484375 68.546875 \r\n",
       "Q 53.21875 62.890625 53.21875 53.421875 \r\n",
       "Q 53.21875 48.921875 51.53125 44.890625 \r\n",
       "Q 49.859375 40.875 45.40625 35.40625 \r\n",
       "Q 44.1875 33.984375 37.640625 27.21875 \r\n",
       "Q 31.109375 20.453125 19.1875 8.296875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-50\"/>\r\n",
       "    </defs>\r\n",
       "    <g transform=\"translate(372.229958 16.318125)scale(0.12 -0.12)\">\r\n",
       "     <use xlink:href=\"#DejaVuSans-50\"/>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "  </g>\r\n",
       "  <g id=\"axes_7\">\r\n",
       "   <g id=\"patch_32\">\r\n",
       "    <path d=\"M 415.769492 79.063888 \r\n",
       "L 472.515254 79.063888 \r\n",
       "L 472.515254 22.318125 \r\n",
       "L 415.769492 22.318125 \r\n",
       "z\r\n",
       "\" style=\"fill:#ffffff;\"/>\r\n",
       "   </g>\r\n",
       "   <g clip-path=\"url(#pb3cc810fba)\">\r\n",
       "    <image height=\"56.88\" id=\"image64be005c54\" transform=\"scale(1 -1)translate(0 -56.88)\" width=\"56.88\" x=\"415.769492\" xlink:href=\"data:image/png;base64,\r\n",
       "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\" y=\"-22.183888\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_33\">\r\n",
       "    <path d=\"M 415.769492 79.063888 \r\n",
       "L 415.769492 22.318125 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_34\">\r\n",
       "    <path d=\"M 472.515254 79.063888 \r\n",
       "L 472.515254 22.318125 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_35\">\r\n",
       "    <path d=\"M 415.769492 79.063888 \r\n",
       "L 472.515254 79.063888 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_36\">\r\n",
       "    <path d=\"M 415.769492 22.318125 \r\n",
       "L 472.515254 22.318125 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"text_7\">\r\n",
       "    <!-- 8 -->\r\n",
       "    <defs>\r\n",
       "     <path d=\"M 31.78125 34.625 \r\n",
       "Q 24.75 34.625 20.71875 30.859375 \r\n",
       "Q 16.703125 27.09375 16.703125 20.515625 \r\n",
       "Q 16.703125 13.921875 20.71875 10.15625 \r\n",
       "Q 24.75 6.390625 31.78125 6.390625 \r\n",
       "Q 38.8125 6.390625 42.859375 10.171875 \r\n",
       "Q 46.921875 13.96875 46.921875 20.515625 \r\n",
       "Q 46.921875 27.09375 42.890625 30.859375 \r\n",
       "Q 38.875 34.625 31.78125 34.625 \r\n",
       "z\r\n",
       "M 21.921875 38.8125 \r\n",
       "Q 15.578125 40.375 12.03125 44.71875 \r\n",
       "Q 8.5 49.078125 8.5 55.328125 \r\n",
       "Q 8.5 64.0625 14.71875 69.140625 \r\n",
       "Q 20.953125 74.21875 31.78125 74.21875 \r\n",
       "Q 42.671875 74.21875 48.875 69.140625 \r\n",
       "Q 55.078125 64.0625 55.078125 55.328125 \r\n",
       "Q 55.078125 49.078125 51.53125 44.71875 \r\n",
       "Q 48 40.375 41.703125 38.8125 \r\n",
       "Q 48.828125 37.15625 52.796875 32.3125 \r\n",
       "Q 56.78125 27.484375 56.78125 20.515625 \r\n",
       "Q 56.78125 9.90625 50.3125 4.234375 \r\n",
       "Q 43.84375 -1.421875 31.78125 -1.421875 \r\n",
       "Q 19.734375 -1.421875 13.25 4.234375 \r\n",
       "Q 6.78125 9.90625 6.78125 20.515625 \r\n",
       "Q 6.78125 27.484375 10.78125 32.3125 \r\n",
       "Q 14.796875 37.15625 21.921875 38.8125 \r\n",
       "z\r\n",
       "M 18.3125 54.390625 \r\n",
       "Q 18.3125 48.734375 21.84375 45.5625 \r\n",
       "Q 25.390625 42.390625 31.78125 42.390625 \r\n",
       "Q 38.140625 42.390625 41.71875 45.5625 \r\n",
       "Q 45.3125 48.734375 45.3125 54.390625 \r\n",
       "Q 45.3125 60.0625 41.71875 63.234375 \r\n",
       "Q 38.140625 66.40625 31.78125 66.40625 \r\n",
       "Q 25.390625 66.40625 21.84375 63.234375 \r\n",
       "Q 18.3125 60.0625 18.3125 54.390625 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-56\"/>\r\n",
       "    </defs>\r\n",
       "    <g transform=\"translate(440.324873 16.318125)scale(0.12 -0.12)\">\r\n",
       "     <use xlink:href=\"#DejaVuSans-56\"/>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "  </g>\r\n",
       "  <g id=\"axes_8\">\r\n",
       "   <g id=\"patch_37\">\r\n",
       "    <path d=\"M 483.864407 79.063888 \r\n",
       "L 540.610169 79.063888 \r\n",
       "L 540.610169 22.318125 \r\n",
       "L 483.864407 22.318125 \r\n",
       "z\r\n",
       "\" style=\"fill:#ffffff;\"/>\r\n",
       "   </g>\r\n",
       "   <g clip-path=\"url(#p3240c4039d)\">\r\n",
       "    <image height=\"56.88\" id=\"image9498454dc1\" transform=\"scale(1 -1)translate(0 -56.88)\" width=\"56.88\" x=\"483.864407\" xlink:href=\"data:image/png;base64,\r\n",
       "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\" y=\"-22.183888\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_38\">\r\n",
       "    <path d=\"M 483.864407 79.063888 \r\n",
       "L 483.864407 22.318125 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_39\">\r\n",
       "    <path d=\"M 540.610169 79.063888 \r\n",
       "L 540.610169 22.318125 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_40\">\r\n",
       "    <path d=\"M 483.864407 79.063888 \r\n",
       "L 540.610169 79.063888 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_41\">\r\n",
       "    <path d=\"M 483.864407 22.318125 \r\n",
       "L 540.610169 22.318125 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"text_8\">\r\n",
       "    <!-- 2 -->\r\n",
       "    <g transform=\"translate(508.419788 16.318125)scale(0.12 -0.12)\">\r\n",
       "     <use xlink:href=\"#DejaVuSans-50\"/>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "  </g>\r\n",
       "  <g id=\"axes_9\">\r\n",
       "   <g id=\"patch_42\">\r\n",
       "    <path d=\"M 551.959322 79.063888 \r\n",
       "L 608.705085 79.063888 \r\n",
       "L 608.705085 22.318125 \r\n",
       "L 551.959322 22.318125 \r\n",
       "z\r\n",
       "\" style=\"fill:#ffffff;\"/>\r\n",
       "   </g>\r\n",
       "   <g clip-path=\"url(#p9abe346066)\">\r\n",
       "    <image height=\"56.88\" id=\"imaged2959277a5\" transform=\"scale(1 -1)translate(0 -56.88)\" width=\"56.88\" x=\"551.959322\" xlink:href=\"data:image/png;base64,\r\n",
       "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\" y=\"-22.183888\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_43\">\r\n",
       "    <path d=\"M 551.959322 79.063888 \r\n",
       "L 551.959322 22.318125 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_44\">\r\n",
       "    <path d=\"M 608.705085 79.063888 \r\n",
       "L 608.705085 22.318125 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_45\">\r\n",
       "    <path d=\"M 551.959322 79.063888 \r\n",
       "L 608.705085 79.063888 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_46\">\r\n",
       "    <path d=\"M 551.959322 22.318125 \r\n",
       "L 608.705085 22.318125 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"text_9\">\r\n",
       "    <!-- 9 -->\r\n",
       "    <defs>\r\n",
       "     <path d=\"M 10.984375 1.515625 \r\n",
       "L 10.984375 10.5 \r\n",
       "Q 14.703125 8.734375 18.5 7.8125 \r\n",
       "Q 22.3125 6.890625 25.984375 6.890625 \r\n",
       "Q 35.75 6.890625 40.890625 13.453125 \r\n",
       "Q 46.046875 20.015625 46.78125 33.40625 \r\n",
       "Q 43.953125 29.203125 39.59375 26.953125 \r\n",
       "Q 35.25 24.703125 29.984375 24.703125 \r\n",
       "Q 19.046875 24.703125 12.671875 31.3125 \r\n",
       "Q 6.296875 37.9375 6.296875 49.421875 \r\n",
       "Q 6.296875 60.640625 12.9375 67.421875 \r\n",
       "Q 19.578125 74.21875 30.609375 74.21875 \r\n",
       "Q 43.265625 74.21875 49.921875 64.515625 \r\n",
       "Q 56.59375 54.828125 56.59375 36.375 \r\n",
       "Q 56.59375 19.140625 48.40625 8.859375 \r\n",
       "Q 40.234375 -1.421875 26.421875 -1.421875 \r\n",
       "Q 22.703125 -1.421875 18.890625 -0.6875 \r\n",
       "Q 15.09375 0.046875 10.984375 1.515625 \r\n",
       "z\r\n",
       "M 30.609375 32.421875 \r\n",
       "Q 37.25 32.421875 41.125 36.953125 \r\n",
       "Q 45.015625 41.5 45.015625 49.421875 \r\n",
       "Q 45.015625 57.28125 41.125 61.84375 \r\n",
       "Q 37.25 66.40625 30.609375 66.40625 \r\n",
       "Q 23.96875 66.40625 20.09375 61.84375 \r\n",
       "Q 16.21875 57.28125 16.21875 49.421875 \r\n",
       "Q 16.21875 41.5 20.09375 36.953125 \r\n",
       "Q 23.96875 32.421875 30.609375 32.421875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-57\"/>\r\n",
       "    </defs>\r\n",
       "    <g transform=\"translate(576.514703 16.318125)scale(0.12 -0.12)\">\r\n",
       "     <use xlink:href=\"#DejaVuSans-57\"/>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "  </g>\r\n",
       "  <g id=\"axes_10\">\r\n",
       "   <g id=\"patch_47\">\r\n",
       "    <path d=\"M 620.054237 79.063888 \r\n",
       "L 676.8 79.063888 \r\n",
       "L 676.8 22.318125 \r\n",
       "L 620.054237 22.318125 \r\n",
       "z\r\n",
       "\" style=\"fill:#ffffff;\"/>\r\n",
       "   </g>\r\n",
       "   <g clip-path=\"url(#p9600661740)\">\r\n",
       "    <image height=\"56.88\" id=\"image73c5b9aead\" transform=\"scale(1 -1)translate(0 -56.88)\" width=\"56.88\" x=\"620.054237\" xlink:href=\"data:image/png;base64,\r\n",
       "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\" y=\"-22.183888\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_48\">\r\n",
       "    <path d=\"M 620.054237 79.063888 \r\n",
       "L 620.054237 22.318125 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_49\">\r\n",
       "    <path d=\"M 676.8 79.063888 \r\n",
       "L 676.8 22.318125 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_50\">\r\n",
       "    <path d=\"M 620.054237 79.063888 \r\n",
       "L 676.8 79.063888 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_51\">\r\n",
       "    <path d=\"M 620.054237 22.318125 \r\n",
       "L 676.8 22.318125 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"text_10\">\r\n",
       "    <!-- 9 -->\r\n",
       "    <g transform=\"translate(644.609619 16.318125)scale(0.12 -0.12)\">\r\n",
       "     <use xlink:href=\"#DejaVuSans-57\"/>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "  </g>\r\n",
       " </g>\r\n",
       " <defs>\r\n",
       "  <clipPath id=\"pde24ffd412\">\r\n",
       "   <rect height=\"56.745763\" width=\"56.745763\" x=\"7.2\" y=\"22.318125\"/>\r\n",
       "  </clipPath>\r\n",
       "  <clipPath id=\"p7d57ef0d92\">\r\n",
       "   <rect height=\"56.745763\" width=\"56.745763\" x=\"75.294915\" y=\"22.318125\"/>\r\n",
       "  </clipPath>\r\n",
       "  <clipPath id=\"p077252f8a2\">\r\n",
       "   <rect height=\"56.745763\" width=\"56.745763\" x=\"143.389831\" y=\"22.318125\"/>\r\n",
       "  </clipPath>\r\n",
       "  <clipPath id=\"p099dadf759\">\r\n",
       "   <rect height=\"56.745763\" width=\"56.745763\" x=\"211.484746\" y=\"22.318125\"/>\r\n",
       "  </clipPath>\r\n",
       "  <clipPath id=\"p37d34cf62d\">\r\n",
       "   <rect height=\"56.745763\" width=\"56.745763\" x=\"279.579661\" y=\"22.318125\"/>\r\n",
       "  </clipPath>\r\n",
       "  <clipPath id=\"pe4ddc55660\">\r\n",
       "   <rect height=\"56.745763\" width=\"56.745763\" x=\"347.674576\" y=\"22.318125\"/>\r\n",
       "  </clipPath>\r\n",
       "  <clipPath id=\"pb3cc810fba\">\r\n",
       "   <rect height=\"56.745763\" width=\"56.745763\" x=\"415.769492\" y=\"22.318125\"/>\r\n",
       "  </clipPath>\r\n",
       "  <clipPath id=\"p3240c4039d\">\r\n",
       "   <rect height=\"56.745763\" width=\"56.745763\" x=\"483.864407\" y=\"22.318125\"/>\r\n",
       "  </clipPath>\r\n",
       "  <clipPath id=\"p9abe346066\">\r\n",
       "   <rect height=\"56.745763\" width=\"56.745763\" x=\"551.959322\" y=\"22.318125\"/>\r\n",
       "  </clipPath>\r\n",
       "  <clipPath id=\"p9600661740\">\r\n",
       "   <rect height=\"56.745763\" width=\"56.745763\" x=\"620.054237\" y=\"22.318125\"/>\r\n",
       "  </clipPath>\r\n",
       " </defs>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<Figure size 1200x1200 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#数据展示\n",
    "from IPython import display\n",
    "\n",
    "def use_svg_display():\n",
    "    # ⽤⽮量图显示\n",
    "    display.set_matplotlib_formats('svg')\n",
    "    \n",
    "def set_figsize(figsize=(4, 3)):\n",
    "    use_svg_display()\n",
    "    # 设置图的尺⼨\n",
    "    plt.rcParams['figure.figsize'] = figsize\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def show_fashion_mnist(images, labels):\n",
    "    use_svg_display()\n",
    "    # 这里的_表示我们忽略（不使用）的变量\n",
    "    _, figs = plt.subplots(1, len(images), figsize=(12, 12))\n",
    "    for f, img, lbl in zip(figs, images, labels):\n",
    "        f.imshow(img.view((28, 28)).numpy())\n",
    "        f.set_title(lbl)\n",
    "        f.axes.get_xaxis().set_visible(False)\n",
    "        f.axes.get_yaxis().set_visible(False)\n",
    "    plt.show()\n",
    "\n",
    "for Xdata, ylabel in train_iter:\n",
    "    break\n",
    "    \n",
    "X, y = [], []\n",
    "for i in range(10):\n",
    "    print(Xdata[i].shape,ylabel[i].numpy())\n",
    "    X.append(Xdata[i]) # 将第i个feature加到X中\n",
    "    y.append(ylabel[i].numpy()) # 将第i个label加到y中\n",
    "show_fashion_mnist(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "graffitiCellId": "id_qw3jw30",
    "id": "Gg8uZka5dbhu",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "因为卷积神经网络计算比多层感知机要复杂，建议使用GPU来加速计算。我们查看看是否可以用GPU，如果成功则使用`cuda:0`，否则仍然使用`cpu`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "graffitiCellId": "id_xnv8h9s",
    "id": "Y3zs_KyHdbhv",
    "jupyter": {},
    "outputId": "da77a9d2-55c9-4781-8132-7ebba7f6f3f6",
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This function has been saved in the d2l package for future use\n",
    "#use GPU\n",
    "def try_gpu():\n",
    "    \"\"\"If GPU is available, return torch.device as cuda:0; else return torch.device as cpu.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    return device\n",
    "\n",
    "device = try_gpu()\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "graffitiCellId": "id_t2kmxh8",
    "id": "nhhHxEjVdbhz",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "我们实现`evaluate_accuracy`函数，该函数用于计算模型`net`在数据集`data_iter`上的准确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "graffitiCellId": "id_x6dxfdo",
    "id": "g4iEi1U8dbh0",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#计算准确率\n",
    "'''\n",
    "(1). net.train()\n",
    "  启用 BatchNormalization 和 Dropout，将BatchNormalization和Dropout置为True\n",
    "(2). net.eval()\n",
    "不启用 BatchNormalization 和 Dropout，将BatchNormalization和Dropout置为False\n",
    "'''\n",
    "\n",
    "def evaluate_accuracy(data_iter, net,device=torch.device('cpu')):\n",
    "    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n",
    "    acc_sum,n = torch.tensor([0],dtype=torch.float32,device=device),0\n",
    "    for X, y in data_iter:\n",
    "        # If device is the GPU, copy the data to the GPU.\n",
    "        X,y = X.to(device),y.to(device)\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            y = y.long()\n",
    "            acc_sum += torch.sum((torch.argmax(net(X), dim=1) == y))  #[[0.2 ,0.4 ,0.5 ,0.6 ,0.8] ,[ 0.1,0.2 ,0.4 ,0.3 ,0.1]] => [ 4 , 2 ]\n",
    "            n += y.shape[0]\n",
    "    return acc_sum.item()/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "graffitiCellId": "id_ccpg4oo",
    "id": "qZj0UJ91dbh3",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "我们定义函数`train_ch5`，用于训练模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "graffitiCellId": "id_e22sitj",
    "id": "WQ8PZBb4dbh4",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#训练函数\n",
    "def train_ch5(net, train_iter, test_iter,criterion, num_epochs, batch_size, device,lr=None):\n",
    "    \"\"\"Train and evaluate a model with CPU or GPU.\"\"\"\n",
    "    print('training on', device)\n",
    "    net.to(device)\n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr)\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum = torch.tensor([0.0],dtype=torch.float32,device=device)\n",
    "        train_acc_sum = torch.tensor([0.0],dtype=torch.float32,device=device)\n",
    "        n, start = 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            # 与net.eval()相反，这里将启用Batch Normalization和Dropout\n",
    "            net.train()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            X,y = X.to(device),y.to(device) \n",
    "            y_hat = net(X)\n",
    "            loss = criterion(y_hat, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                y = y.long()\n",
    "                train_l_sum += loss.float()\n",
    "                train_acc_sum += (torch.sum((torch.argmax(y_hat, dim=1) == y))).float()\n",
    "                n += y.shape[0]\n",
    "        test_acc = evaluate_accuracy(test_iter, net,device)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\n",
    "              'time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum/n, train_acc_sum/n, test_acc,\n",
    "                 time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "graffitiCellId": "id_o8t94tl",
    "id": "QCTjn-iRdbh6",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "我们重新将模型参数初始化到对应的设备`device`(`cpu` or `cuda:0`)之上，并使用Xavier随机初始化。损失函数和训练算法则依然使用交叉熵损失函数和小批量随机梯度下降。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "graffitiCellId": "id_k8iyyir",
    "id": "SRwnEh4ndbh7",
    "jupyter": {},
    "outputId": "abcc9495-ed33-41a2-c6f5-7bcb8b82c3e4",
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cuda:0\n",
      "epoch 1, loss 0.0090, train acc 0.111, test acc 0.280, time 7.3 sec\n",
      "epoch 2, loss 0.0045, train acc 0.535, test acc 0.612, time 7.2 sec\n",
      "epoch 3, loss 0.0031, train acc 0.687, test acc 0.681, time 7.4 sec\n",
      "epoch 4, loss 0.0027, train acc 0.730, test acc 0.748, time 7.2 sec\n",
      "epoch 5, loss 0.0025, train acc 0.755, test acc 0.713, time 7.2 sec\n",
      "epoch 6, loss 0.0023, train acc 0.777, test acc 0.761, time 7.1 sec\n",
      "epoch 7, loss 0.0021, train acc 0.796, test acc 0.796, time 7.0 sec\n",
      "epoch 8, loss 0.0020, train acc 0.808, test acc 0.780, time 7.2 sec\n",
      "epoch 9, loss 0.0019, train acc 0.821, test acc 0.803, time 7.4 sec\n",
      "epoch 10, loss 0.0018, train acc 0.832, test acc 0.784, time 7.1 sec\n"
     ]
    }
   ],
   "source": [
    "# 训练\n",
    "lr, num_epochs = 0.9, 10\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "net.apply(init_weights)\n",
    "net = net.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()   #交叉熵描述了两个概率分布之间的距离，交叉熵越小说明两者之间越接近\n",
    "train_ch5(net, train_iter, test_iter, criterion,num_epochs, batch_size,device, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cuda:0\n",
      "epoch 1, loss 0.0017, train acc 0.845, test acc 0.834, time 7.6 sec\n",
      "epoch 2, loss 0.0016, train acc 0.847, test acc 0.835, time 7.1 sec\n",
      "epoch 3, loss 0.0016, train acc 0.848, test acc 0.835, time 7.3 sec\n",
      "epoch 4, loss 0.0016, train acc 0.848, test acc 0.836, time 7.3 sec\n",
      "epoch 5, loss 0.0016, train acc 0.849, test acc 0.838, time 7.3 sec\n",
      "epoch 6, loss 0.0016, train acc 0.850, test acc 0.837, time 7.1 sec\n",
      "epoch 7, loss 0.0016, train acc 0.851, test acc 0.838, time 7.5 sec\n",
      "epoch 8, loss 0.0016, train acc 0.852, test acc 0.838, time 7.2 sec\n",
      "epoch 9, loss 0.0016, train acc 0.852, test acc 0.839, time 7.1 sec\n",
      "epoch 10, loss 0.0016, train acc 0.852, test acc 0.840, time 7.4 sec\n",
      "epoch 11, loss 0.0016, train acc 0.853, test acc 0.842, time 7.3 sec\n",
      "epoch 12, loss 0.0016, train acc 0.853, test acc 0.842, time 7.3 sec\n",
      "epoch 13, loss 0.0016, train acc 0.854, test acc 0.842, time 7.1 sec\n",
      "epoch 14, loss 0.0016, train acc 0.855, test acc 0.842, time 7.2 sec\n",
      "epoch 15, loss 0.0016, train acc 0.854, test acc 0.844, time 7.0 sec\n",
      "epoch 16, loss 0.0016, train acc 0.856, test acc 0.844, time 6.9 sec\n",
      "epoch 17, loss 0.0015, train acc 0.856, test acc 0.843, time 7.0 sec\n",
      "epoch 18, loss 0.0015, train acc 0.857, test acc 0.846, time 7.0 sec\n",
      "epoch 19, loss 0.0015, train acc 0.857, test acc 0.847, time 7.1 sec\n",
      "epoch 20, loss 0.0015, train acc 0.857, test acc 0.848, time 7.1 sec\n",
      "training on cuda:0\n",
      "epoch 1, loss 0.0016, train acc 0.854, test acc 0.826, time 7.0 sec\n",
      "epoch 2, loss 0.0015, train acc 0.856, test acc 0.845, time 6.9 sec\n",
      "epoch 3, loss 0.0015, train acc 0.858, test acc 0.842, time 7.0 sec\n",
      "epoch 4, loss 0.0015, train acc 0.859, test acc 0.844, time 6.8 sec\n",
      "epoch 5, loss 0.0015, train acc 0.860, test acc 0.852, time 6.9 sec\n",
      "epoch 6, loss 0.0015, train acc 0.863, test acc 0.852, time 6.9 sec\n",
      "epoch 7, loss 0.0014, train acc 0.865, test acc 0.852, time 7.0 sec\n",
      "epoch 8, loss 0.0014, train acc 0.867, test acc 0.854, time 7.3 sec\n",
      "epoch 9, loss 0.0014, train acc 0.869, test acc 0.851, time 7.1 sec\n",
      "epoch 10, loss 0.0014, train acc 0.869, test acc 0.858, time 7.0 sec\n",
      "epoch 11, loss 0.0014, train acc 0.871, test acc 0.848, time 6.9 sec\n",
      "epoch 12, loss 0.0014, train acc 0.872, test acc 0.868, time 7.0 sec\n",
      "epoch 13, loss 0.0013, train acc 0.873, test acc 0.861, time 6.9 sec\n",
      "epoch 14, loss 0.0013, train acc 0.875, test acc 0.846, time 6.9 sec\n",
      "epoch 15, loss 0.0013, train acc 0.877, test acc 0.863, time 6.8 sec\n",
      "epoch 16, loss 0.0013, train acc 0.877, test acc 0.862, time 7.0 sec\n",
      "epoch 17, loss 0.0013, train acc 0.880, test acc 0.855, time 7.2 sec\n",
      "epoch 18, loss 0.0013, train acc 0.880, test acc 0.858, time 7.2 sec\n",
      "epoch 19, loss 0.0013, train acc 0.882, test acc 0.866, time 7.1 sec\n",
      "epoch 20, loss 0.0013, train acc 0.882, test acc 0.862, time 7.2 sec\n",
      "training on cuda:0\n",
      "epoch 1, loss 0.0014, train acc 0.870, test acc 0.856, time 7.2 sec\n",
      "epoch 2, loss 0.0013, train acc 0.877, test acc 0.849, time 7.3 sec\n",
      "epoch 3, loss 0.0013, train acc 0.879, test acc 0.870, time 7.1 sec\n",
      "epoch 4, loss 0.0013, train acc 0.880, test acc 0.865, time 7.6 sec\n",
      "epoch 5, loss 0.0012, train acc 0.883, test acc 0.870, time 7.2 sec\n",
      "epoch 6, loss 0.0012, train acc 0.885, test acc 0.856, time 7.0 sec\n",
      "epoch 7, loss 0.0012, train acc 0.887, test acc 0.840, time 7.3 sec\n",
      "epoch 8, loss 0.0012, train acc 0.887, test acc 0.869, time 7.2 sec\n",
      "epoch 9, loss 0.0012, train acc 0.889, test acc 0.861, time 7.3 sec\n",
      "epoch 10, loss 0.0012, train acc 0.891, test acc 0.820, time 7.2 sec\n",
      "epoch 11, loss 0.0011, train acc 0.891, test acc 0.837, time 7.3 sec\n",
      "epoch 12, loss 0.0011, train acc 0.893, test acc 0.845, time 7.4 sec\n",
      "epoch 13, loss 0.0011, train acc 0.894, test acc 0.883, time 7.4 sec\n",
      "epoch 14, loss 0.0011, train acc 0.894, test acc 0.865, time 7.4 sec\n",
      "epoch 15, loss 0.0011, train acc 0.895, test acc 0.868, time 7.3 sec\n",
      "epoch 16, loss 0.0011, train acc 0.896, test acc 0.883, time 7.2 sec\n",
      "epoch 17, loss 0.0011, train acc 0.899, test acc 0.873, time 7.4 sec\n",
      "epoch 18, loss 0.0011, train acc 0.899, test acc 0.878, time 7.1 sec\n",
      "epoch 19, loss 0.0011, train acc 0.900, test acc 0.870, time 7.4 sec\n",
      "epoch 20, loss 0.0011, train acc 0.901, test acc 0.871, time 7.2 sec\n",
      "training on cuda:0\n",
      "epoch 1, loss 0.0011, train acc 0.898, test acc 0.858, time 7.3 sec\n",
      "epoch 2, loss 0.0011, train acc 0.897, test acc 0.883, time 7.0 sec\n",
      "epoch 3, loss 0.0010, train acc 0.902, test acc 0.871, time 7.3 sec\n",
      "epoch 4, loss 0.0010, train acc 0.902, test acc 0.879, time 7.2 sec\n",
      "epoch 5, loss 0.0010, train acc 0.902, test acc 0.883, time 7.1 sec\n",
      "epoch 6, loss 0.0010, train acc 0.903, test acc 0.891, time 7.4 sec\n",
      "epoch 7, loss 0.0010, train acc 0.904, test acc 0.891, time 7.3 sec\n",
      "epoch 8, loss 0.0010, train acc 0.906, test acc 0.884, time 7.2 sec\n",
      "epoch 9, loss 0.0010, train acc 0.905, test acc 0.881, time 7.3 sec\n",
      "epoch 10, loss 0.0010, train acc 0.906, test acc 0.886, time 7.4 sec\n",
      "epoch 11, loss 0.0010, train acc 0.908, test acc 0.885, time 7.1 sec\n",
      "epoch 12, loss 0.0010, train acc 0.909, test acc 0.876, time 7.1 sec\n",
      "epoch 13, loss 0.0010, train acc 0.909, test acc 0.885, time 7.6 sec\n",
      "epoch 14, loss 0.0009, train acc 0.908, test acc 0.897, time 7.5 sec\n",
      "epoch 15, loss 0.0009, train acc 0.911, test acc 0.891, time 7.4 sec\n",
      "epoch 16, loss 0.0009, train acc 0.911, test acc 0.893, time 7.5 sec\n",
      "epoch 17, loss 0.0009, train acc 0.912, test acc 0.893, time 7.2 sec\n",
      "epoch 18, loss 0.0009, train acc 0.913, test acc 0.895, time 8.0 sec\n",
      "epoch 19, loss 0.0009, train acc 0.914, test acc 0.892, time 7.3 sec\n",
      "epoch 20, loss 0.0009, train acc 0.914, test acc 0.897, time 7.4 sec\n",
      "training on cuda:0\n",
      "epoch 1, loss 0.0010, train acc 0.908, test acc 0.888, time 7.5 sec\n",
      "epoch 2, loss 0.0009, train acc 0.911, test acc 0.862, time 7.3 sec\n",
      "epoch 3, loss 0.0009, train acc 0.911, test acc 0.874, time 7.8 sec\n",
      "epoch 4, loss 0.0009, train acc 0.913, test acc 0.856, time 7.4 sec\n",
      "epoch 5, loss 0.0009, train acc 0.914, test acc 0.882, time 7.4 sec\n",
      "epoch 6, loss 0.0009, train acc 0.915, test acc 0.890, time 7.9 sec\n",
      "epoch 7, loss 0.0009, train acc 0.915, test acc 0.894, time 7.6 sec\n",
      "epoch 8, loss 0.0009, train acc 0.916, test acc 0.900, time 7.3 sec\n",
      "epoch 9, loss 0.0009, train acc 0.918, test acc 0.891, time 8.0 sec\n",
      "epoch 10, loss 0.0009, train acc 0.918, test acc 0.867, time 7.3 sec\n",
      "epoch 11, loss 0.0008, train acc 0.919, test acc 0.902, time 7.7 sec\n",
      "epoch 12, loss 0.0008, train acc 0.920, test acc 0.868, time 7.9 sec\n",
      "epoch 13, loss 0.0008, train acc 0.921, test acc 0.881, time 8.4 sec\n",
      "epoch 14, loss 0.0008, train acc 0.921, test acc 0.884, time 7.6 sec\n",
      "epoch 15, loss 0.0008, train acc 0.922, test acc 0.901, time 8.6 sec\n",
      "epoch 16, loss 0.0008, train acc 0.922, test acc 0.900, time 7.5 sec\n",
      "epoch 17, loss 0.0008, train acc 0.923, test acc 0.893, time 7.3 sec\n",
      "epoch 18, loss 0.0008, train acc 0.924, test acc 0.876, time 7.2 sec\n",
      "epoch 19, loss 0.0008, train acc 0.926, test acc 0.894, time 7.5 sec\n",
      "epoch 20, loss 0.0008, train acc 0.925, test acc 0.898, time 8.7 sec\n",
      "training on cpu\n",
      "epoch 1, loss 0.0007, train acc 0.935, test acc 0.908, time 47.9 sec\n",
      "epoch 2, loss 0.0007, train acc 0.936, test acc 0.908, time 48.2 sec\n",
      "epoch 3, loss 0.0007, train acc 0.937, test acc 0.908, time 48.7 sec\n",
      "epoch 4, loss 0.0007, train acc 0.937, test acc 0.907, time 47.6 sec\n",
      "epoch 5, loss 0.0007, train acc 0.937, test acc 0.908, time 48.0 sec\n",
      "epoch 6, loss 0.0007, train acc 0.937, test acc 0.907, time 49.2 sec\n",
      "epoch 7, loss 0.0007, train acc 0.937, test acc 0.907, time 48.0 sec\n",
      "epoch 8, loss 0.0007, train acc 0.937, test acc 0.907, time 44.9 sec\n",
      "epoch 9, loss 0.0007, train acc 0.937, test acc 0.909, time 47.0 sec\n",
      "epoch 10, loss 0.0007, train acc 0.938, test acc 0.906, time 47.2 sec\n",
      "epoch 11, loss 0.0007, train acc 0.938, test acc 0.909, time 47.9 sec\n",
      "epoch 12, loss 0.0007, train acc 0.937, test acc 0.907, time 47.3 sec\n",
      "epoch 13, loss 0.0007, train acc 0.938, test acc 0.909, time 47.3 sec\n",
      "epoch 14, loss 0.0007, train acc 0.937, test acc 0.907, time 47.4 sec\n",
      "epoch 15, loss 0.0007, train acc 0.938, test acc 0.907, time 48.2 sec\n",
      "epoch 16, loss 0.0007, train acc 0.938, test acc 0.907, time 49.0 sec\n",
      "epoch 17, loss 0.0007, train acc 0.938, test acc 0.907, time 46.9 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, loss 0.0007, train acc 0.938, test acc 0.908, time 43.3 sec\n",
      "epoch 19, loss 0.0007, train acc 0.938, test acc 0.907, time 44.5 sec\n",
      "epoch 20, loss 0.0007, train acc 0.938, test acc 0.908, time 44.4 sec\n",
      "training on cpu\n",
      "epoch 1, loss 0.0007, train acc 0.936, test acc 0.905, time 44.1 sec\n",
      "epoch 2, loss 0.0007, train acc 0.936, test acc 0.907, time 45.2 sec\n",
      "epoch 3, loss 0.0007, train acc 0.937, test acc 0.908, time 43.4 sec\n",
      "epoch 4, loss 0.0007, train acc 0.937, test acc 0.907, time 44.0 sec\n",
      "epoch 5, loss 0.0007, train acc 0.937, test acc 0.906, time 44.3 sec\n",
      "epoch 6, loss 0.0007, train acc 0.937, test acc 0.906, time 42.4 sec\n",
      "epoch 7, loss 0.0007, train acc 0.938, test acc 0.904, time 45.3 sec\n",
      "epoch 8, loss 0.0007, train acc 0.938, test acc 0.907, time 43.8 sec\n",
      "epoch 9, loss 0.0007, train acc 0.938, test acc 0.906, time 43.4 sec\n",
      "epoch 10, loss 0.0007, train acc 0.938, test acc 0.904, time 50.1 sec\n",
      "epoch 11, loss 0.0006, train acc 0.938, test acc 0.904, time 44.8 sec\n",
      "epoch 12, loss 0.0006, train acc 0.939, test acc 0.903, time 44.4 sec\n",
      "epoch 13, loss 0.0006, train acc 0.939, test acc 0.901, time 44.4 sec\n",
      "epoch 14, loss 0.0006, train acc 0.939, test acc 0.906, time 44.5 sec\n",
      "epoch 15, loss 0.0006, train acc 0.939, test acc 0.907, time 43.5 sec\n",
      "epoch 16, loss 0.0006, train acc 0.940, test acc 0.904, time 43.5 sec\n",
      "epoch 17, loss 0.0006, train acc 0.940, test acc 0.905, time 46.2 sec\n",
      "epoch 18, loss 0.0006, train acc 0.941, test acc 0.904, time 41.9 sec\n",
      "epoch 19, loss 0.0006, train acc 0.941, test acc 0.906, time 42.2 sec\n",
      "epoch 20, loss 0.0006, train acc 0.941, test acc 0.904, time 44.4 sec\n",
      "training on cpu\n",
      "epoch 1, loss 0.0007, train acc 0.937, test acc 0.890, time 45.9 sec\n",
      "epoch 2, loss 0.0007, train acc 0.936, test acc 0.901, time 42.4 sec\n",
      "epoch 3, loss 0.0007, train acc 0.937, test acc 0.899, time 42.4 sec\n",
      "epoch 4, loss 0.0007, train acc 0.938, test acc 0.900, time 42.7 sec\n",
      "epoch 5, loss 0.0006, train acc 0.938, test acc 0.905, time 43.2 sec\n",
      "epoch 6, loss 0.0006, train acc 0.939, test acc 0.901, time 42.9 sec\n",
      "epoch 7, loss 0.0006, train acc 0.939, test acc 0.897, time 42.8 sec\n",
      "epoch 8, loss 0.0006, train acc 0.939, test acc 0.903, time 43.8 sec\n",
      "epoch 9, loss 0.0006, train acc 0.940, test acc 0.906, time 43.3 sec\n",
      "epoch 10, loss 0.0006, train acc 0.940, test acc 0.898, time 42.7 sec\n",
      "epoch 11, loss 0.0006, train acc 0.941, test acc 0.902, time 42.9 sec\n",
      "epoch 12, loss 0.0006, train acc 0.940, test acc 0.904, time 42.6 sec\n",
      "epoch 13, loss 0.0006, train acc 0.941, test acc 0.900, time 43.2 sec\n",
      "epoch 14, loss 0.0006, train acc 0.941, test acc 0.902, time 43.8 sec\n",
      "epoch 15, loss 0.0006, train acc 0.942, test acc 0.900, time 43.2 sec\n",
      "epoch 16, loss 0.0006, train acc 0.940, test acc 0.903, time 45.0 sec\n",
      "epoch 17, loss 0.0006, train acc 0.943, test acc 0.904, time 45.5 sec\n",
      "epoch 18, loss 0.0006, train acc 0.942, test acc 0.906, time 45.8 sec\n",
      "epoch 19, loss 0.0006, train acc 0.943, test acc 0.895, time 45.6 sec\n",
      "epoch 20, loss 0.0006, train acc 0.943, test acc 0.903, time 44.7 sec\n",
      "training on cpu\n",
      "epoch 1, loss 0.0006, train acc 0.940, test acc 0.885, time 44.9 sec\n",
      "epoch 2, loss 0.0006, train acc 0.941, test acc 0.893, time 49.0 sec\n",
      "epoch 3, loss 0.0006, train acc 0.942, test acc 0.868, time 49.3 sec\n",
      "epoch 4, loss 0.0006, train acc 0.941, test acc 0.873, time 46.1 sec\n",
      "epoch 5, loss 0.0006, train acc 0.943, test acc 0.906, time 50.1 sec\n",
      "epoch 6, loss 0.0006, train acc 0.943, test acc 0.905, time 45.9 sec\n",
      "epoch 7, loss 0.0006, train acc 0.944, test acc 0.903, time 46.6 sec\n",
      "epoch 8, loss 0.0006, train acc 0.943, test acc 0.895, time 216.1 sec\n",
      "epoch 9, loss 0.0006, train acc 0.945, test acc 0.899, time 35.9 sec\n",
      "epoch 10, loss 0.0006, train acc 0.944, test acc 0.899, time 35.7 sec\n",
      "epoch 11, loss 0.0006, train acc 0.946, test acc 0.893, time 34.7 sec\n",
      "epoch 12, loss 0.0006, train acc 0.945, test acc 0.881, time 35.2 sec\n",
      "epoch 13, loss 0.0006, train acc 0.947, test acc 0.888, time 35.0 sec\n",
      "epoch 14, loss 0.0006, train acc 0.946, test acc 0.884, time 34.6 sec\n",
      "epoch 15, loss 0.0006, train acc 0.947, test acc 0.906, time 35.0 sec\n",
      "epoch 16, loss 0.0006, train acc 0.947, test acc 0.904, time 35.3 sec\n",
      "epoch 17, loss 0.0005, train acc 0.948, test acc 0.860, time 34.9 sec\n",
      "epoch 18, loss 0.0005, train acc 0.948, test acc 0.896, time 34.6 sec\n",
      "epoch 19, loss 0.0005, train acc 0.948, test acc 0.899, time 34.7 sec\n",
      "epoch 20, loss 0.0005, train acc 0.950, test acc 0.890, time 35.4 sec\n",
      "training on cpu\n",
      "epoch 1, loss 0.0006, train acc 0.939, test acc 0.899, time 34.6 sec\n",
      "epoch 2, loss 0.0006, train acc 0.942, test acc 0.902, time 34.4 sec\n",
      "epoch 3, loss 0.0006, train acc 0.945, test acc 0.898, time 35.0 sec\n",
      "epoch 4, loss 0.0006, train acc 0.945, test acc 0.897, time 34.8 sec\n",
      "epoch 5, loss 0.0006, train acc 0.945, test acc 0.897, time 34.4 sec\n",
      "epoch 6, loss 0.0006, train acc 0.946, test acc 0.898, time 34.3 sec\n",
      "epoch 7, loss 0.0005, train acc 0.946, test acc 0.876, time 34.7 sec\n",
      "epoch 8, loss 0.0006, train acc 0.947, test acc 0.894, time 34.4 sec\n",
      "epoch 9, loss 0.0005, train acc 0.947, test acc 0.899, time 35.1 sec\n",
      "epoch 10, loss 0.0005, train acc 0.951, test acc 0.896, time 35.1 sec\n",
      "epoch 11, loss 0.0005, train acc 0.948, test acc 0.906, time 34.5 sec\n",
      "epoch 12, loss 0.0005, train acc 0.950, test acc 0.905, time 34.4 sec\n",
      "epoch 13, loss 0.0005, train acc 0.950, test acc 0.900, time 34.5 sec\n",
      "epoch 14, loss 0.0005, train acc 0.951, test acc 0.897, time 34.9 sec\n",
      "epoch 15, loss 0.0005, train acc 0.953, test acc 0.900, time 34.7 sec\n",
      "epoch 16, loss 0.0005, train acc 0.951, test acc 0.894, time 34.5 sec\n",
      "epoch 17, loss 0.0005, train acc 0.951, test acc 0.893, time 34.6 sec\n",
      "epoch 18, loss 0.0005, train acc 0.952, test acc 0.884, time 34.8 sec\n",
      "epoch 19, loss 0.0005, train acc 0.954, test acc 0.895, time 34.5 sec\n",
      "epoch 20, loss 0.0005, train acc 0.954, test acc 0.900, time 34.5 sec\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "for device in [torch.device(\"cuda:0\"), torch.device(\"cpu\")]:\n",
    "    for lr in [0.1, 0.5, 0.9, 1.1, 1.5]:\n",
    "        train_ch5(net, train_iter, test_iter, criterion,num_epochs, batch_size,device, lr)\n",
    "# Average on gpu:7.4s\n",
    "# Average on cpu:47s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "graffitiCellId": "id_y3tdhvt",
    "id": "6C2C48F49CD24FB38F6B313B6EC1983F",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 28, 28]) torch.Size([256])\n",
      "tensor([9, 2, 1, 1, 6, 1, 4, 6, 5, 7, 4, 5, 5, 3, 4, 1, 2, 2, 8, 0])\n",
      "tensor([9, 2, 1, 1, 6, 1, 4, 6, 5, 7, 4, 5, 7, 3, 4, 1, 2, 4, 8, 0])\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "for testdata,testlabe in test_iter:\n",
    "    testdata,testlabe = testdata.to(device),testlabe.to(device)\n",
    "    break\n",
    "print(testdata.shape,testlabe.shape)\n",
    "net.eval()\n",
    "y_pre = net(testdata)\n",
    "print(torch.argmax(y_pre,dim=1)[:20])\n",
    "print(testlabe[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "graffitiCellId": "id_xwmnzx5",
    "id": "pRUx8zxq1XmD",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 总结：\n",
    "\n",
    "卷积神经网络就是含卷积层的网络。\n",
    "LeNet交替使用卷积层和最大池化层后接全连接层来进行图像分类。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
