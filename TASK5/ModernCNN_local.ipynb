{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3700F0383ACD456594322246327904AB",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    " # 深度卷积神经网络（AlexNet） "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E59CD3957F874D2D9FB1B0D7C1A3566C",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "LeNet:  在大的真实数据集上的表现并不尽如⼈意。     \n",
    "1.神经网络计算复杂。  \n",
    "2.还没有⼤量深⼊研究参数初始化和⾮凸优化算法等诸多领域。  \n",
    "  \n",
    "机器学习的特征提取:手工定义的特征提取函数  \n",
    "神经网络的特征提取：通过学习得到数据的多级表征，并逐级表⽰越来越抽象的概念或模式。  \n",
    "  \n",
    "神经网络发展的限制:数据、硬件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "894A96EBC1404E008C042A83D1A053F9",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### AlexNet\n",
    "首次证明了学习到的特征可以超越⼿⼯设计的特征，从而⼀举打破计算机视觉研究的前状。   \n",
    "**特征：**\n",
    "1. 8层变换，其中有5层卷积和2层全连接隐藏层，以及1个全连接输出层。\n",
    "2. 将sigmoid激活函数改成了更加简单的ReLU激活函数。\n",
    "3. 用Dropout来控制全连接层的模型复杂度。\n",
    "4. 引入数据增强，如翻转、裁剪和颜色变化，从而进一步扩大数据集来缓解过拟合。\n",
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/image/q5kv4gpx88.png?imageView2/0/w/640/h/640)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "DD41B540CFAB491B9D43105C3D90647C",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#目前GPU算力资源预计17日上线，在此之前本代码只能使用CPU运行。\n",
    "#考虑到本代码中的模型过大，CPU训练较慢，\n",
    "#我们还将代码上传了一份到 https://www.kaggle.com/boyuai/boyu-d2l-modernconvolutionalnetwork\n",
    "#如希望提前使用gpu运行请至kaggle。\n",
    "\n",
    "\n",
    "import time\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 96, 11, 4), # in_channels, out_channels, kernel_size, stride, padding\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2), # kernel_size, stride\n",
    "            # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数\n",
    "            nn.Conv2d(96, 256, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2),\n",
    "            # 连续3个卷积层，且使用更小的卷积窗口。除了最后的卷积层外，进一步增大了输出通道数。\n",
    "            # 前两个卷积层后不使用池化层来减小输入的高和宽\n",
    "            nn.Conv2d(256, 384, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 384, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2)\n",
    "        )\n",
    "         # 这里全连接层的输出个数比LeNet中的大数倍。使用丢弃层来缓解过拟合\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256*5*5, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            #由于使用CPU镜像，精简网络，若为GPU镜像可添加该层\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            # 输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000\n",
    "            nn.Linear(4096, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "\n",
    "        feature = self.conv(img)\n",
    "        output = self.fc(feature.view(img.shape[0], -1))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "237401462039416F8B5874A7DA7FD9F2",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(1, 96, kernel_size=(11, 11), stride=(4, 4))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU()\n",
      "    (10): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU()\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=6400, out_features=4096, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = AlexNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EEF29AB29F37460C84C492FCE02FEF2D",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 载入数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "8994A770DF884A5D87F60737C50D0A1F",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = torch.Size([16, 1, 224, 224]) \n",
      "Y = tensor([7, 5, 1, 9, 7, 1, 1, 1, 1, 7, 1, 3, 3, 5, 4, 5], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# 本函数已保存在d2lzh_pytorch包中方便以后使用\n",
    "def load_data_fashion_mnist(batch_size, resize=None, \n",
    "                            root='C:\\\\jupyter_notebook\\\\boyu\\\\datasets\\\\FashionMNIST2065\\\\FashionMNIST'):\n",
    "    \"\"\"Download the fashion mnist dataset and then load into memory.\"\"\"\n",
    "    trans = []\n",
    "    if resize:\n",
    "        trans.append(torchvision.transforms.Resize(size=resize))\n",
    "    trans.append(torchvision.transforms.ToTensor())\n",
    "    \n",
    "    transform = torchvision.transforms.Compose(trans)\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(root=root, train=True, download=True, transform=transform)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(root=root, train=False, download=True, transform=transform)\n",
    "    \n",
    "#     print(len(mnist_train))\n",
    "    train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    return train_iter, test_iter\n",
    "\n",
    "#batchsize=128\n",
    "batch_size = 16\n",
    "# 如出现“out of memory”的报错信息，可减小batch_size或resize\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size,224)\n",
    "for X, Y in train_iter:\n",
    "    print('X =', X.shape,\n",
    "        '\\nY =', Y.type(torch.int32))\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B3671547A0D04495B5B1F2ADE856500F",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net,device=torch.device('cpu')):\n",
    "    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n",
    "    acc_sum,n = torch.tensor([0],dtype=torch.float32,device=device),0\n",
    "    for X, y in data_iter:\n",
    "        # If device is the GPU, copy the data to the GPU.\n",
    "        X,y = X.to(device),y.to(device)\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            y = y.long()\n",
    "            acc_sum += torch.sum((torch.argmax(net(X), dim=1) == y))  #[[0.2 ,0.4 ,0.5 ,0.6 ,0.8] ,[ 0.1,0.2 ,0.4 ,0.3 ,0.1]] => [ 4 , 2 ]\n",
    "            n += y.shape[0]\n",
    "    return acc_sum.item()/n\n",
    "\n",
    "#训练函数\n",
    "def train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs, lr=None):\n",
    "    \"\"\"Train and evaluate a model with CPU or GPU.\"\"\"\n",
    "    print('training on', device)\n",
    "    print(\"batch_size\", batch_size)\n",
    "    print(\"optimizer\", optimizer)\n",
    "    print(\"num_epochs\", num_epochs)\n",
    "    net.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    threshold = 600\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum = torch.tensor([0.0],dtype=torch.float32,device=device)\n",
    "        train_acc_sum = torch.tensor([0.0],dtype=torch.float32,device=device)\n",
    "        n, start = 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            # 与net.eval()相反，这里将启用Batch Normalization和Dropout\n",
    "            net.train()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            X,y = X.to(device),y.to(device) \n",
    "            y_hat = net(X)\n",
    "            loss = criterion(y_hat, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "#             print(net[0])\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                y = y.long()\n",
    "                train_l_sum += loss.float()\n",
    "                train_acc_sum += (torch.sum((torch.argmax(y_hat, dim=1) == y))).float()\n",
    "                n += y.shape[0]\n",
    "            \n",
    "            if n > threshold:\n",
    "                break\n",
    "            \n",
    "        test_acc = evaluate_accuracy(test_iter, net,device)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\n",
    "              'time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum/n, train_acc_sum/n, test_acc,\n",
    "                 time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "FB33F7F4BEE1486187254524422FDF80",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cuda\n",
      "epoch 1, loss 0.0360, train acc 0.784, test acc 0.842, time 828.0 sec\n",
      "epoch 2, loss 0.0250, train acc 0.852, test acc 0.855, time 827.5 sec\n",
      "epoch 3, loss 0.0231, train acc 0.863, test acc 0.866, time 828.8 sec\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "lr, num_epochs = 0.001, 3\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C40CCB5CDD8E4D3B9A6264B03CBEEB76",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#  使用重复元素的网络（VGG）\n",
    "VGG：通过重复使⽤简单的基础块来构建深度模型。  \n",
    "Block:数个相同的填充为1、窗口形状为$3\\times 3$的卷积层,接上一个步幅为2、窗口形状为$2\\times 2$的最大池化层。  \n",
    "卷积层保持输入的高和宽不变，而池化层则对其减半。\n",
    "\n",
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/image/q5l6vut7h1.png?imageView2/0/w/640/h/640)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F3D1E7D0AC154E6A99842D587608E870",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### VGG11的简单实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlattenLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FlattenLayer, self).__init__()\n",
    "    def forward(self, x): # x 的形状: (batch, *, *, ...)\n",
    "        return x.view(x.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "AA4AB087A263436B90B719085FEABC67",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def vgg_block(num_convs, in_channels, out_channels): #卷积层个数，输入通道数，输出通道数\n",
    "    blk = []\n",
    "    for i in range(num_convs):\n",
    "        if i == 0:\n",
    "            blk.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "        else:\n",
    "            blk.append(nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1))\n",
    "        blk.append(nn.ReLU())\n",
    "    blk.append(nn.MaxPool2d(kernel_size=2, stride=2)) # 这里会使宽高减半\n",
    "    return nn.Sequential(*blk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3199FD641C1F417FA3C6B65784A20CF2",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "conv_arch = ((1, 1, 64), (1, 64, 128), (2, 128, 256), (2, 256, 512), (2, 512, 512))\n",
    "# 经过5个vgg_block, 宽高会减半5次, 变成 224/32 = 7\n",
    "fc_features = 512 * 7 * 7 # c * w * h\n",
    "fc_hidden_units = 4096 # 任意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "08AA6A69F80B4DAC8FA831C6E5C9260B",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def vgg(conv_arch, fc_features, fc_hidden_units=4096):\n",
    "    net = nn.Sequential()\n",
    "    # 卷积层部分\n",
    "    for i, (num_convs, in_channels, out_channels) in enumerate(conv_arch):\n",
    "        # 每经过一个vgg_block都会使宽高减半\n",
    "        net.add_module(\"vgg_block_\" + str(i+1), vgg_block(num_convs, in_channels, out_channels))\n",
    "    # 全连接层部分\n",
    "    net.add_module(\"fc\", nn.Sequential(FlattenLayer(),\n",
    "                                 nn.Linear(fc_features, fc_hidden_units),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.5),\n",
    "                                 nn.Linear(fc_hidden_units, fc_hidden_units),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.5),\n",
    "                                 nn.Linear(fc_hidden_units, 10)\n",
    "                                ))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "A5FDDE9D6C404D868E3AB5E1731043D9",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg_block_1 output shape:  torch.Size([1, 64, 112, 112])\n",
      "vgg_block_2 output shape:  torch.Size([1, 128, 56, 56])\n",
      "vgg_block_3 output shape:  torch.Size([1, 256, 28, 28])\n",
      "vgg_block_4 output shape:  torch.Size([1, 512, 14, 14])\n",
      "vgg_block_5 output shape:  torch.Size([1, 512, 7, 7])\n",
      "fc output shape:  torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "net = vgg(conv_arch, fc_features, fc_hidden_units)\n",
    "X = torch.rand(1, 1, 224, 224)\n",
    "\n",
    "# named_children获取一级子模块及其名字(named_modules会返回所有子模块,包括子模块的子模块)\n",
    "for name, blk in net.named_children(): \n",
    "    X = blk(X)\n",
    "    print(name, 'output shape: ', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "40A6F9278D034D4A874189A1F8F52ABF",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (vgg_block_1): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (vgg_block_2): Sequential(\n",
      "    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (vgg_block_3): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (vgg_block_4): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (vgg_block_5): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): FlattenLayer()\n",
      "    (1): Linear(in_features=3136, out_features=512, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Dropout(p=0.5, inplace=False)\n",
      "    (7): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "ratio = 8\n",
    "small_conv_arch = [(1, 1, 64//ratio), (1, 64//ratio, 128//ratio), (2, 128//ratio, 256//ratio), \n",
    "                   (2, 256//ratio, 512//ratio), (2, 512//ratio, 512//ratio)]\n",
    "net = vgg(small_conv_arch, fc_features // ratio, fc_hidden_units // ratio)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "5325FD0A7DB64D43809A660129617282",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cuda\n",
      "epoch 1, loss 0.0327, train acc 0.806, test acc 0.869, time 300.2 sec\n",
      "epoch 2, loss 0.0204, train acc 0.883, test acc 0.897, time 297.3 sec\n",
      "epoch 3, loss 0.0178, train acc 0.897, test acc 0.908, time 300.5 sec\n",
      "epoch 4, loss 0.0162, train acc 0.905, test acc 0.907, time 297.9 sec\n",
      "epoch 5, loss 0.0152, train acc 0.913, test acc 0.915, time 298.0 sec\n"
     ]
    }
   ],
   "source": [
    "batchsize=16\n",
    "#batch_size = 64\n",
    "# 如出现“out of memory”的报错信息，可减小batch_size或resize\n",
    "# train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)\n",
    "\n",
    "lr, num_epochs = 0.001, 5\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7D83E04F316B4D0B933654E2F9FB08B9",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#  ⽹络中的⽹络（NiN） \n",
    "LeNet、AlexNet和VGG：先以由卷积层构成的模块充分抽取 空间特征，再以由全连接层构成的模块来输出分类结果。  \n",
    "NiN：串联多个由卷积层和“全连接”层构成的小⽹络来构建⼀个深层⽹络。  \n",
    "⽤了输出通道数等于标签类别数的NiN块，然后使⽤全局平均池化层对每个通道中所有元素求平均并直接⽤于分类。  \n",
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/image/q5l6u1p5vy.png?imageView2/0/w/960/h/960)\n",
    "\n",
    "1×1卷积核作用   \n",
    "1.放缩通道数：通过控制卷积核的数量达到通道数的放缩。  \n",
    "2.增加非线性。1×1卷积核的卷积过程相当于全连接层的计算过程，并且还加入了非线性激活函数，从而可以增加网络的非线性。  \n",
    "3.计算参数少   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "88FB988FED1F4CB08417E01A3C560459",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def nin_block(in_channels, out_channels, kernel_size, stride, padding):\n",
    "    blk = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Conv2d(out_channels, out_channels, kernel_size=1),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Conv2d(out_channels, out_channels, kernel_size=1),\n",
    "                        nn.ReLU())\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "AB1A33FE0F1C451F87F390FEC87D334E",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 已保存在d2lzh_pytorch\n",
    "class GlobalAvgPool2d(nn.Module):\n",
    "    # 全局平均池化层可通过将池化窗口形状设置成输入的高和宽实现\n",
    "    def __init__(self):\n",
    "        super(GlobalAvgPool2d, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return F.avg_pool2d(x, kernel_size=x.size()[2:])\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nin_block(1, 96, kernel_size=11, stride=4, padding=0),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    nin_block(96, 256, kernel_size=5, stride=1, padding=2),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    nin_block(256, 384, kernel_size=3, stride=1, padding=1),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2), \n",
    "    nn.Dropout(0.5),\n",
    "    # 标签类别数是10\n",
    "    nin_block(384, 10, kernel_size=3, stride=1, padding=1),\n",
    "    GlobalAvgPool2d(), \n",
    "    # 将四维的输出转成二维的输出，其形状为(批量大小, 10)\n",
    "    FlattenLayer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "08C2986CBEEF40F98825FC6FF163C572",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.2249, 0.0000, 0.1529, 0.0000, 0.0000, 0.0203, 0.1160, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.2255, 0.0000, 0.1515, 0.0000, 0.0000, 0.0203, 0.1166, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.2255, 0.0000, 0.1510, 0.0000, 0.0000, 0.0204, 0.1173, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.2255, 0.0000, 0.1522, 0.0000, 0.0000, 0.0202, 0.1153, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.2247, 0.0000, 0.1524, 0.0000, 0.0000, 0.0205, 0.1163, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.2254, 0.0000, 0.1526, 0.0000, 0.0000, 0.0206, 0.1157, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.2249, 0.0000, 0.1522, 0.0000, 0.0000, 0.0203, 0.1166, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.2253, 0.0000, 0.1525, 0.0000, 0.0000, 0.0207, 0.1163, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.2253, 0.0000, 0.1524, 0.0000, 0.0000, 0.0205, 0.1154, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.2252, 0.0000, 0.1520, 0.0000, 0.0000, 0.0205, 0.1163, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.2253, 0.0000, 0.1529, 0.0000, 0.0000, 0.0202, 0.1153, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.2252, 0.0000, 0.1527, 0.0000, 0.0000, 0.0207, 0.1165, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.2253, 0.0000, 0.1524, 0.0000, 0.0000, 0.0201, 0.1159, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.2250, 0.0000, 0.1519, 0.0000, 0.0000, 0.0201, 0.1165, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.2243, 0.0000, 0.1519, 0.0000, 0.0000, 0.0200, 0.1164, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.2248, 0.0000, 0.1519, 0.0000, 0.0000, 0.0203, 0.1164, 0.0000,\n",
      "         0.0000]], grad_fn=<ViewBackward>)\n",
      "tensor([False, False,  True, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(16, 1, 224, 224)\n",
    "for name, blk in net.named_children(): \n",
    "    X = blk(X)\n",
    "#     print(name, 'output shape: ', X.shape)\n",
    "print(X)\n",
    "y_hat = X\n",
    "print((torch.argmax(y_hat, dim=1) == Y))\n",
    "# print(Y)\n",
    "# loss = nn.CrossEntropyLoss()\n",
    "# print(loss(X, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Conv2d(1, 96, kernel_size=(11, 11), stride=(4, 4))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (2): Sequential(\n",
      "    (0): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (4): Sequential(\n",
      "    (0): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (6): Dropout(p=0.5, inplace=False)\n",
      "  (7): Sequential(\n",
      "    (0): Conv2d(384, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(10, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(10, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (8): GlobalAvgPool2d()\n",
      "  (9): FlattenLayer()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "DBD61B6A08E1400996DCB60B4B570818",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cuda\n",
      "batch_size 128\n",
      "optimizer Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.002\n",
      "    weight_decay: 0\n",
      ")\n",
      "num_epochs 5\n",
      "epoch 1, loss 0.0314, train acc 0.818, test acc 0.821, time 456.6 sec\n",
      "epoch 2, loss 0.0292, train acc 0.830, test acc 0.835, time 455.6 sec\n",
      "epoch 3, loss 0.0278, train acc 0.838, test acc 0.840, time 454.9 sec\n",
      "epoch 4, loss 0.0267, train acc 0.844, test acc 0.838, time 454.8 sec\n",
      "epoch 5, loss 0.0257, train acc 0.850, test acc 0.842, time 455.0 sec\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "# 如出现“out of memory”的报错信息，可减小batch_size或resize\n",
    "#train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)\n",
    "\n",
    "lr, num_epochs = 0.002, 5\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AE1E233B008843DEB6E582ECFEE65617",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "NiN重复使⽤由卷积层和代替全连接层的1×1卷积层构成的NiN块来构建深层⽹络。  \n",
    "NiN去除了容易造成过拟合的全连接输出层，而是将其替换成输出通道数等于标签类别数 的NiN块和全局平均池化层。   \n",
    "NiN的以上设计思想影响了后⾯⼀系列卷积神经⽹络的设计。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7886126F79424D75863FB4B09025CE40",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# GoogLeNet\n",
    "1. 由Inception基础块组成。  \n",
    "2. Inception块相当于⼀个有4条线路的⼦⽹络。它通过不同窗口形状的卷积层和最⼤池化层来并⾏抽取信息，并使⽤1×1卷积层减少通道数从而降低模型复杂度。   \n",
    "3. 可以⾃定义的超参数是每个层的输出通道数，我们以此来控制模型复杂度。 \n",
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/image/q5l6uortw.png?imageView2/0/w/640/h/640)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "E9CBC745630F489CB69A0001B076F199",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class Inception(nn.Module):\n",
    "    # c1 - c4为每条线路里的层的输出通道数\n",
    "    def __init__(self, in_c, c1, c2, c3, c4):\n",
    "        super(Inception, self).__init__()\n",
    "        # 线路1，单1 x 1卷积层\n",
    "        self.p1_1 = nn.Conv2d(in_c, c1, kernel_size=1)\n",
    "        # 线路2，1 x 1卷积层后接3 x 3卷积层\n",
    "        self.p2_1 = nn.Conv2d(in_c, c2[0], kernel_size=1)\n",
    "        self.p2_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)\n",
    "        # 线路3，1 x 1卷积层后接5 x 5卷积层\n",
    "        self.p3_1 = nn.Conv2d(in_c, c3[0], kernel_size=1)\n",
    "        self.p3_2 = nn.Conv2d(c3[0], c3[1], kernel_size=5, padding=2)\n",
    "        # 线路4，3 x 3最大池化层后接1 x 1卷积层\n",
    "        self.p4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.p4_2 = nn.Conv2d(in_c, c4, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        p1 = F.relu(self.p1_1(x))\n",
    "        p2 = F.relu(self.p2_2(F.relu(self.p2_1(x))))\n",
    "        p3 = F.relu(self.p3_2(F.relu(self.p3_1(x))))\n",
    "        p4 = F.relu(self.p4_2(self.p4_1(x)))\n",
    "        return torch.cat((p1, p2, p3, p4), dim=1)  # 在通道维上连结输出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4C63967592040D9BD9D31D7078999DC",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### GoogLeNet模型\n",
    "完整模型结构  \n",
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/image/q5l6x0fyyn.png?imageView2/0/w/640/h/640)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "566939FB07C646D380806E2CA941FD85",
    "jupyter": {},
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: tensor([[[[0.4016, 0.2945, 0.2131,  ..., 0.6686, 0.5561, 0.7743],\n",
      "          [0.0321, 0.2801, 0.6308,  ..., 0.8031, 0.8587, 0.1036],\n",
      "          [0.2816, 0.0558, 0.9636,  ..., 0.5752, 0.2536, 0.6632],\n",
      "          ...,\n",
      "          [0.1710, 0.9704, 0.7551,  ..., 0.0352, 0.6006, 0.9137],\n",
      "          [0.0271, 0.7339, 0.3625,  ..., 0.4912, 0.0643, 0.3125],\n",
      "          [0.8709, 0.7905, 0.3299,  ..., 0.7673, 0.8530, 0.8899]]],\n",
      "\n",
      "\n",
      "        [[[0.0799, 0.6055, 0.8935,  ..., 0.1542, 0.4079, 0.3033],\n",
      "          [0.5553, 0.2808, 0.2601,  ..., 0.5986, 0.8623, 0.5848],\n",
      "          [0.7704, 0.7595, 0.9363,  ..., 0.2626, 0.6852, 0.3641],\n",
      "          ...,\n",
      "          [0.9968, 0.5470, 0.4161,  ..., 0.0116, 0.8394, 0.1587],\n",
      "          [0.8318, 0.0346, 0.8026,  ..., 0.1560, 0.4954, 0.9921],\n",
      "          [0.1923, 0.7876, 0.1538,  ..., 0.7745, 0.6702, 0.8152]]],\n",
      "\n",
      "\n",
      "        [[[0.3459, 0.9643, 0.6856,  ..., 0.2577, 0.9101, 0.7442],\n",
      "          [0.9963, 0.7252, 0.7825,  ..., 0.0870, 0.3300, 0.2287],\n",
      "          [0.8255, 0.8132, 0.5368,  ..., 0.1286, 0.2294, 0.6591],\n",
      "          ...,\n",
      "          [0.6599, 0.0893, 0.3607,  ..., 0.9922, 0.7254, 0.5040],\n",
      "          [0.1832, 0.5877, 0.3780,  ..., 0.3498, 0.8917, 0.6075],\n",
      "          [0.7774, 0.6074, 0.7325,  ..., 0.1174, 0.6487, 0.5799]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.9281, 0.3142, 0.6734,  ..., 0.8124, 0.1751, 0.5489],\n",
      "          [0.3200, 0.7970, 0.3705,  ..., 0.3211, 0.2926, 0.3470],\n",
      "          [0.1371, 0.0922, 0.5447,  ..., 0.6099, 0.2176, 0.0321],\n",
      "          ...,\n",
      "          [0.5280, 0.2364, 0.5264,  ..., 0.6478, 0.0673, 0.6296],\n",
      "          [0.2413, 0.4361, 0.8963,  ..., 0.5574, 0.7100, 0.2916],\n",
      "          [0.5757, 0.9715, 0.8153,  ..., 0.0309, 0.4115, 0.6362]]],\n",
      "\n",
      "\n",
      "        [[[0.1127, 0.8436, 0.3950,  ..., 0.3360, 0.9839, 0.3488],\n",
      "          [0.1909, 0.8031, 0.0362,  ..., 0.1903, 0.1593, 0.3395],\n",
      "          [0.6132, 0.4781, 0.1534,  ..., 0.5570, 0.6359, 0.7311],\n",
      "          ...,\n",
      "          [0.6213, 0.5565, 0.7913,  ..., 0.5023, 0.8707, 0.7263],\n",
      "          [0.2110, 0.2193, 0.5326,  ..., 0.6297, 0.7296, 0.6730],\n",
      "          [0.0500, 0.1422, 0.0030,  ..., 0.2549, 0.8219, 0.4830]]],\n",
      "\n",
      "\n",
      "        [[[0.8274, 0.9905, 0.5435,  ..., 0.2264, 0.6585, 0.1710],\n",
      "          [0.2374, 0.2736, 0.4997,  ..., 0.3428, 0.9193, 0.8906],\n",
      "          [0.4419, 0.2932, 0.9420,  ..., 0.3390, 0.4591, 0.1514],\n",
      "          ...,\n",
      "          [0.1497, 0.5850, 0.5206,  ..., 0.0344, 0.6053, 0.0209],\n",
      "          [0.4734, 0.7646, 0.8447,  ..., 0.2497, 0.6400, 0.8769],\n",
      "          [0.0120, 0.1874, 0.4056,  ..., 0.8921, 0.7078, 0.8920]]]])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sequential(\n",
      "  (0): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "  (1): ReLU()\n",
      "  (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      ")\n",
      "tensor([[[[0.0000e+00, 1.3310e-01, 2.1985e-01,  ..., 3.3514e-01,\n",
      "           3.3514e-01, 2.2604e-01],\n",
      "          [4.9119e-03, 2.2226e-01, 2.2883e-01,  ..., 2.7378e-01,\n",
      "           2.1523e-01, 3.1202e-01],\n",
      "          [1.4666e-01, 1.8728e-01, 2.7284e-01,  ..., 2.4565e-01,\n",
      "           3.9948e-01, 3.8122e-01],\n",
      "          ...,\n",
      "          [4.5388e-01, 4.5388e-01, 4.0946e-01,  ..., 3.2335e-01,\n",
      "           4.0752e-01, 4.1761e-01],\n",
      "          [4.5388e-01, 4.5388e-01, 3.6361e-01,  ..., 4.2228e-01,\n",
      "           4.2228e-01, 4.6152e-01],\n",
      "          [2.6446e-01, 2.9757e-01, 3.6361e-01,  ..., 4.2228e-01,\n",
      "           4.2228e-01, 3.3294e-01]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 2.4013e-02,  ..., 0.0000e+00,\n",
      "           2.5821e-02, 2.5821e-02],\n",
      "          [0.0000e+00, 0.0000e+00, 2.4013e-02,  ..., 1.0931e-02,\n",
      "           2.5821e-02, 8.3361e-02],\n",
      "          [0.0000e+00, 0.0000e+00, 4.0906e-02,  ..., 2.4009e-01,\n",
      "           2.4009e-01, 1.1152e-01],\n",
      "          ...,\n",
      "          [1.3327e-01, 1.5630e-01, 7.0882e-02,  ..., 1.1895e-01,\n",
      "           9.1179e-02, 1.3520e-01],\n",
      "          [1.0851e-01, 1.5630e-01, 1.7143e-03,  ..., 1.1895e-01,\n",
      "           9.9347e-02, 2.2509e-01],\n",
      "          [2.0465e-01, 2.1681e-01, 3.4507e-01,  ..., 1.6502e-01,\n",
      "           2.2089e-01, 2.2509e-01]],\n",
      "\n",
      "         [[2.0993e-01, 3.6552e-01, 4.1851e-01,  ..., 5.2414e-01,\n",
      "           5.9323e-01, 4.3947e-01],\n",
      "          [3.1390e-01, 4.1153e-01, 4.1851e-01,  ..., 5.2414e-01,\n",
      "           5.9323e-01, 4.3947e-01],\n",
      "          [3.9718e-01, 4.1153e-01, 5.2312e-01,  ..., 3.3419e-01,\n",
      "           4.2105e-01, 3.7548e-01],\n",
      "          ...,\n",
      "          [2.8436e-01, 5.7128e-01, 5.7128e-01,  ..., 4.9217e-01,\n",
      "           5.9759e-01, 5.9759e-01],\n",
      "          [3.8848e-01, 4.5987e-01, 4.8321e-01,  ..., 4.6760e-01,\n",
      "           5.1959e-01, 5.1959e-01],\n",
      "          [3.8848e-01, 3.8848e-01, 3.7281e-01,  ..., 4.6760e-01,\n",
      "           7.2977e-01, 5.1959e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           1.6734e-02, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           3.8131e-04, 1.1210e-02],\n",
      "          [0.0000e+00, 0.0000e+00, 6.5725e-02,  ..., 1.6660e-01,\n",
      "           1.6660e-01, 0.0000e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 1.5040e-02, 1.5040e-02,  ..., 0.0000e+00,\n",
      "           4.2258e-02, 1.4095e-01],\n",
      "          [0.0000e+00, 1.5040e-02, 1.5040e-02,  ..., 0.0000e+00,\n",
      "           5.5785e-03, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           1.8433e-02, 1.8433e-02]],\n",
      "\n",
      "         [[1.1115e-01, 4.2349e-01, 4.2349e-01,  ..., 1.1352e-01,\n",
      "           2.0907e-02, 2.0292e-01],\n",
      "          [1.1115e-01, 4.2349e-01, 4.2349e-01,  ..., 1.8629e-01,\n",
      "           1.9113e-01, 4.8809e-01],\n",
      "          [9.1618e-02, 1.4478e-01, 3.3990e-01,  ..., 2.1535e-01,\n",
      "           1.8629e-01, 4.8809e-01],\n",
      "          ...,\n",
      "          [2.7586e-01, 2.8826e-01, 2.8826e-01,  ..., 4.1568e-01,\n",
      "           4.1568e-01, 2.0200e-01],\n",
      "          [3.0386e-01, 3.0386e-01, 3.6560e-01,  ..., 2.8924e-01,\n",
      "           4.1091e-01, 4.1091e-01],\n",
      "          [3.0386e-01, 3.1663e-01, 3.6560e-01,  ..., 2.7975e-01,\n",
      "           3.3064e-01, 3.7941e-01]]],\n",
      "\n",
      "\n",
      "        [[[7.3655e-02, 2.3479e-01, 1.9658e-01,  ..., 3.3186e-01,\n",
      "           2.9709e-01, 1.9795e-01],\n",
      "          [8.8668e-02, 4.3900e-01, 3.1732e-01,  ..., 2.2435e-01,\n",
      "           2.8453e-01, 4.4544e-01],\n",
      "          [2.2983e-01, 2.2983e-01, 2.2187e-01,  ..., 3.1968e-01,\n",
      "           3.8967e-01, 3.8967e-01],\n",
      "          ...,\n",
      "          [1.9983e-01, 2.9694e-01, 1.8513e-01,  ..., 2.5519e-01,\n",
      "           3.3014e-01, 4.0234e-01],\n",
      "          [4.2649e-01, 4.2649e-01, 3.5516e-01,  ..., 2.5262e-01,\n",
      "           2.6309e-01, 4.0750e-01],\n",
      "          [4.2649e-01, 4.2649e-01, 2.8428e-01,  ..., 2.5262e-01,\n",
      "           4.3060e-01, 4.0750e-01]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           4.4047e-02, 2.6227e-02],\n",
      "          [5.8072e-04, 4.0224e-02, 1.0694e-01,  ..., 6.1281e-02,\n",
      "           4.4047e-02, 1.5274e-01],\n",
      "          [1.0078e-01, 1.0078e-01, 1.0694e-01,  ..., 7.9320e-02,\n",
      "           0.0000e+00, 1.5274e-01],\n",
      "          ...,\n",
      "          [0.0000e+00, 2.9768e-02, 9.9580e-02,  ..., 8.6111e-02,\n",
      "           1.3658e-01, 2.2064e-01],\n",
      "          [7.8202e-03, 7.8202e-03, 1.5571e-02,  ..., 9.5268e-02,\n",
      "           9.5268e-02, 2.2064e-01],\n",
      "          [2.5697e-01, 2.5697e-01, 2.5461e-01,  ..., 1.8229e-01,\n",
      "           2.3482e-01, 2.3482e-01]],\n",
      "\n",
      "         [[3.7252e-01, 4.7746e-01, 4.7746e-01,  ..., 2.8989e-01,\n",
      "           5.2609e-01, 4.1085e-01],\n",
      "          [5.3055e-01, 5.3055e-01, 5.0489e-01,  ..., 3.7687e-01,\n",
      "           4.8115e-01, 6.3557e-01],\n",
      "          [4.1867e-01, 4.7088e-01, 4.9135e-01,  ..., 6.6001e-01,\n",
      "           5.4443e-01, 6.3557e-01],\n",
      "          ...,\n",
      "          [3.9172e-01, 3.9172e-01, 5.9606e-01,  ..., 4.7481e-01,\n",
      "           4.4795e-01, 2.8587e-01],\n",
      "          [4.4468e-01, 4.4468e-01, 4.6472e-01,  ..., 4.8608e-01,\n",
      "           2.9349e-01, 3.8782e-01],\n",
      "          [4.4468e-01, 4.4468e-01, 3.2247e-01,  ..., 4.8608e-01,\n",
      "           2.4166e-01, 3.8782e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 2.7854e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 4.4901e-02,  ..., 2.1809e-01,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 2.3163e-01, 4.4901e-02,  ..., 2.1809e-01,\n",
      "           5.9497e-02, 5.4736e-02],\n",
      "          [0.0000e+00, 2.3163e-01, 0.0000e+00,  ..., 5.9497e-02,\n",
      "           5.9497e-02, 5.4736e-02]],\n",
      "\n",
      "         [[2.0693e-01, 3.5000e-02, 2.8476e-02,  ..., 1.4172e-01,\n",
      "           1.4172e-01, 2.8329e-01],\n",
      "          [2.0693e-01, 2.5541e-01, 2.5541e-01,  ..., 2.2298e-01,\n",
      "           2.5667e-01, 2.8329e-01],\n",
      "          [1.3904e-01, 2.8004e-01, 2.1238e-01,  ..., 2.3793e-01,\n",
      "           5.3264e-01, 5.3264e-01],\n",
      "          ...,\n",
      "          [9.9300e-02, 2.0226e-01, 3.0034e-01,  ..., 2.3765e-01,\n",
      "           2.3765e-01, 2.0924e-01],\n",
      "          [2.4413e-01, 1.6927e-01, 2.3959e-01,  ..., 2.0470e-01,\n",
      "           1.9432e-01, 1.1380e-01],\n",
      "          [2.4413e-01, 1.9101e-01, 2.3959e-01,  ..., 3.5557e-01,\n",
      "           3.5557e-01, 2.0439e-01]]],\n",
      "\n",
      "\n",
      "        [[[1.7625e-01, 3.8510e-01, 1.2536e-01,  ..., 1.7265e-01,\n",
      "           2.0935e-01, 2.8576e-01],\n",
      "          [4.9399e-02, 2.2178e-01, 2.3380e-01,  ..., 2.6990e-01,\n",
      "           2.6990e-01, 4.1128e-01],\n",
      "          [2.5841e-01, 2.5841e-01, 2.3380e-01,  ..., 1.5024e-01,\n",
      "           2.5814e-01, 3.9563e-01],\n",
      "          ...,\n",
      "          [9.3807e-02, 4.2796e-01, 4.2796e-01,  ..., 3.2171e-01,\n",
      "           3.2171e-01, 4.1007e-01],\n",
      "          [2.2254e-01, 3.4140e-01, 2.9177e-01,  ..., 2.8396e-01,\n",
      "           2.2383e-01, 3.1826e-01],\n",
      "          [2.5877e-01, 2.9059e-01, 3.3175e-01,  ..., 2.4071e-01,\n",
      "           3.0650e-01, 3.0646e-01]],\n",
      "\n",
      "         [[7.2091e-02, 7.2091e-02, 0.0000e+00,  ..., 9.2239e-02,\n",
      "           9.2239e-02, 1.5889e-01],\n",
      "          [1.5368e-01, 1.5368e-01, 1.0084e-01,  ..., 1.0502e-01,\n",
      "           9.2239e-02, 2.6225e-01],\n",
      "          [1.7522e-02, 8.6352e-02, 3.3424e-02,  ..., 7.4834e-02,\n",
      "           0.0000e+00, 2.6225e-01],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 2.0566e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 1.6404e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 2.6887e-01,  ..., 5.4846e-02,\n",
      "           0.0000e+00, 1.9466e-01],\n",
      "          [0.0000e+00, 2.1828e-01, 2.1828e-01,  ..., 1.3827e-01,\n",
      "           1.4959e-01, 1.9466e-01]],\n",
      "\n",
      "         [[3.5550e-01, 4.4859e-01, 5.3898e-01,  ..., 3.7250e-01,\n",
      "           4.8762e-01, 4.8762e-01],\n",
      "          [3.5550e-01, 4.8535e-01, 5.3898e-01,  ..., 4.1939e-01,\n",
      "           5.4115e-01, 5.4115e-01],\n",
      "          [3.3040e-01, 5.3754e-01, 5.1249e-01,  ..., 5.9920e-01,\n",
      "           5.9707e-01, 5.9707e-01],\n",
      "          ...,\n",
      "          [3.9004e-01, 4.8711e-01, 5.0167e-01,  ..., 4.9842e-01,\n",
      "           4.2702e-01, 5.8867e-01],\n",
      "          [3.5920e-01, 6.7943e-01, 6.7943e-01,  ..., 3.3889e-01,\n",
      "           4.4588e-01, 5.6647e-01],\n",
      "          [3.6244e-01, 6.4289e-01, 3.4322e-01,  ..., 3.7178e-01,\n",
      "           4.4588e-01, 4.4588e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[0.0000e+00, 5.7629e-02, 5.7629e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.1354e-03,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.9245e-02,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [1.6541e-02, 0.0000e+00, 0.0000e+00,  ..., 2.0613e-01,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.0482e-02,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.1930e-02,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[1.0799e-01, 6.8273e-02, 6.8273e-02,  ..., 9.6189e-02,\n",
      "           9.6189e-02, 3.7945e-02],\n",
      "          [1.4229e-01, 2.7080e-01, 3.9039e-01,  ..., 3.5868e-01,\n",
      "           3.4447e-01, 2.9694e-01],\n",
      "          [1.6928e-01, 2.3612e-01, 3.9039e-01,  ..., 3.5868e-01,\n",
      "           3.4447e-01, 2.9741e-01],\n",
      "          ...,\n",
      "          [1.6670e-01, 3.6238e-01, 2.0311e-01,  ..., 3.9689e-01,\n",
      "           4.0077e-01, 2.0397e-01],\n",
      "          [2.0676e-01, 2.0676e-01, 2.3842e-01,  ..., 3.2104e-01,\n",
      "           4.0077e-01, 2.2623e-01],\n",
      "          [2.2515e-01, 2.4686e-01, 2.3842e-01,  ..., 3.2073e-01,\n",
      "           3.7308e-01, 3.7308e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[2.9126e-02, 2.3533e-01, 2.4352e-01,  ..., 2.5874e-01,\n",
      "           6.8723e-02, 3.7091e-01],\n",
      "          [8.8762e-02, 3.0663e-01, 3.5187e-01,  ..., 5.3883e-01,\n",
      "           1.2841e-01, 3.7091e-01],\n",
      "          [1.9866e-01, 3.0627e-01, 3.6386e-01,  ..., 5.3883e-01,\n",
      "           9.5277e-02, 3.0330e-01],\n",
      "          ...,\n",
      "          [4.7697e-02, 3.6046e-01, 3.6581e-01,  ..., 3.9892e-01,\n",
      "           3.9892e-01, 3.9730e-01],\n",
      "          [1.8640e-01, 3.0063e-01, 3.0063e-01,  ..., 3.3354e-01,\n",
      "           3.8720e-01, 2.8713e-01],\n",
      "          [1.0247e-01, 3.5948e-01, 3.5948e-01,  ..., 9.5848e-02,\n",
      "           1.0000e-01, 2.9475e-01]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 9.1880e-02,\n",
      "           0.0000e+00, 7.5609e-02],\n",
      "          [0.0000e+00, 8.1093e-02, 8.1093e-02,  ..., 1.9130e-01,\n",
      "           0.0000e+00, 1.4533e-01],\n",
      "          [0.0000e+00, 8.1093e-02, 1.5207e-01,  ..., 3.3984e-01,\n",
      "           0.0000e+00, 1.1475e-01],\n",
      "          ...,\n",
      "          [0.0000e+00, 1.6177e-01, 1.6177e-01,  ..., 5.6285e-02,\n",
      "           5.6285e-02, 3.1642e-01],\n",
      "          [0.0000e+00, 2.9287e-02, 0.0000e+00,  ..., 1.6983e-01,\n",
      "           1.6983e-01, 3.1642e-01],\n",
      "          [1.2997e-01, 1.6166e-01, 1.4200e-01,  ..., 8.3930e-02,\n",
      "           1.7701e-01, 1.9081e-01]],\n",
      "\n",
      "         [[1.9574e-01, 2.6861e-01, 4.4822e-01,  ..., 3.4818e-01,\n",
      "           4.4330e-01, 4.6867e-01],\n",
      "          [3.7396e-01, 3.9634e-01, 5.9923e-01,  ..., 4.5827e-01,\n",
      "           4.4330e-01, 4.6867e-01],\n",
      "          [3.7396e-01, 4.0285e-01, 4.0285e-01,  ..., 3.6616e-01,\n",
      "           4.0276e-01, 4.0209e-01],\n",
      "          ...,\n",
      "          [6.0610e-01, 6.0610e-01, 4.1327e-01,  ..., 5.1393e-01,\n",
      "           4.3700e-01, 4.1948e-01],\n",
      "          [3.3448e-01, 3.8552e-01, 4.1327e-01,  ..., 5.5149e-01,\n",
      "           6.2925e-01, 6.2925e-01],\n",
      "          [3.7468e-01, 3.8552e-01, 3.8552e-01,  ..., 4.4217e-01,\n",
      "           4.3368e-01, 4.2303e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 2.0187e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 2.0187e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           7.9598e-02, 0.0000e+00],\n",
      "          ...,\n",
      "          [4.7497e-02, 0.0000e+00, 1.6418e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [4.7497e-02, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           2.0093e-03, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[6.7883e-02, 2.7019e-01, 7.1404e-03,  ..., 7.5341e-02,\n",
      "           7.5341e-02, 4.2552e-02],\n",
      "          [5.9729e-02, 3.0474e-01, 4.2091e-01,  ..., 2.2988e-01,\n",
      "           2.5594e-01, 2.5594e-01],\n",
      "          [1.2831e-01, 3.0474e-01, 2.2571e-01,  ..., 2.4231e-01,\n",
      "           2.5594e-01, 2.5594e-01],\n",
      "          ...,\n",
      "          [3.3862e-01, 1.5950e-01, 2.4877e-01,  ..., 3.5273e-01,\n",
      "           3.4973e-01, 3.4973e-01],\n",
      "          [2.9841e-01, 2.9841e-01, 2.0507e-01,  ..., 5.2486e-01,\n",
      "           2.8563e-01, 2.2358e-01],\n",
      "          [1.7552e-01, 2.3457e-01, 2.3457e-01,  ..., 1.2670e-01,\n",
      "           2.8025e-01, 2.2358e-01]]],\n",
      "\n",
      "\n",
      "        [[[3.3092e-01, 3.3092e-01, 1.1508e-01,  ..., 3.0702e-01,\n",
      "           2.2950e-01, 2.2950e-01],\n",
      "          [3.3092e-01, 3.8812e-01, 3.2367e-01,  ..., 5.5930e-01,\n",
      "           2.2695e-01, 2.2359e-01],\n",
      "          [2.7875e-01, 2.7875e-01, 2.2701e-01,  ..., 2.9764e-01,\n",
      "           2.9764e-01, 3.3224e-01],\n",
      "          ...,\n",
      "          [9.5042e-02, 4.1919e-01, 4.1919e-01,  ..., 1.9597e-01,\n",
      "           2.7226e-01, 2.8713e-01],\n",
      "          [1.6071e-01, 4.1919e-01, 4.2533e-01,  ..., 2.5787e-01,\n",
      "           2.7226e-01, 3.4604e-01],\n",
      "          [0.0000e+00, 3.5735e-01, 3.6189e-01,  ..., 2.6076e-01,\n",
      "           2.9620e-01, 3.4604e-01]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.9107e-01,\n",
      "           0.0000e+00, 8.7527e-03],\n",
      "          [0.0000e+00, 0.0000e+00, 6.5052e-02,  ..., 1.9107e-01,\n",
      "           7.2179e-02, 1.1229e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 6.5052e-02,  ..., 6.9248e-02,\n",
      "           3.5711e-01, 1.3556e-01],\n",
      "          ...,\n",
      "          [9.6025e-02, 9.8302e-02, 9.8302e-02,  ..., 9.4079e-02,\n",
      "           9.4079e-02, 7.9751e-02],\n",
      "          [0.0000e+00, 7.8918e-02, 9.6497e-02,  ..., 9.4079e-02,\n",
      "           9.4079e-02, 6.0051e-02],\n",
      "          [0.0000e+00, 3.6503e-01, 3.6510e-01,  ..., 1.3089e-01,\n",
      "           1.5926e-01, 1.0920e-01]],\n",
      "\n",
      "         [[1.9125e-01, 4.9263e-01, 4.9263e-01,  ..., 2.7533e-01,\n",
      "           6.0865e-01, 6.0865e-01],\n",
      "          [3.0129e-01, 4.9791e-01, 4.9263e-01,  ..., 4.6267e-01,\n",
      "           6.0865e-01, 6.0865e-01],\n",
      "          [4.1169e-01, 4.9791e-01, 5.0553e-01,  ..., 5.7430e-01,\n",
      "           6.0272e-01, 4.7322e-01],\n",
      "          ...,\n",
      "          [3.9055e-01, 4.4580e-01, 3.8885e-01,  ..., 5.4157e-01,\n",
      "           4.1097e-01, 5.0249e-01],\n",
      "          [4.5453e-01, 4.5453e-01, 3.3679e-01,  ..., 4.5850e-01,\n",
      "           4.4124e-01, 3.8228e-01],\n",
      "          [4.5453e-01, 4.5453e-01, 4.4015e-01,  ..., 4.6544e-01,\n",
      "           5.4390e-01, 5.4390e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[0.0000e+00, 4.4214e-02, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           1.0997e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 7.1131e-02, 7.1131e-02,  ..., 0.0000e+00,\n",
      "           1.0997e-01, 7.3615e-02],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.1862e-02,\n",
      "           2.3327e-01, 4.6343e-02],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.8733e-02,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.8733e-02,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[8.0586e-02, 1.5124e-01, 1.5124e-01,  ..., 1.0703e-01,\n",
      "           1.0703e-01, 2.4463e-02],\n",
      "          [1.9340e-01, 2.6723e-01, 2.6723e-01,  ..., 1.6963e-01,\n",
      "           2.0091e-01, 3.4293e-01],\n",
      "          [2.7281e-01, 2.6723e-01, 2.6723e-01,  ..., 4.7878e-01,\n",
      "           2.0091e-01, 2.0091e-01],\n",
      "          ...,\n",
      "          [2.1337e-01, 2.1089e-01, 2.8587e-01,  ..., 2.4359e-01,\n",
      "           2.4031e-01, 2.2580e-01],\n",
      "          [2.1337e-01, 2.9625e-01, 2.9625e-01,  ..., 2.4574e-01,\n",
      "           3.0806e-01, 3.0806e-01],\n",
      "          [3.4344e-01, 3.4344e-01, 2.9625e-01,  ..., 2.3058e-01,\n",
      "           3.0806e-01, 3.0806e-01]]],\n",
      "\n",
      "\n",
      "        [[[1.5637e-01, 1.9461e-01, 1.5123e-01,  ..., 2.9450e-01,\n",
      "           2.9450e-01, 1.9995e-01],\n",
      "          [1.8572e-01, 1.9461e-01, 4.7420e-01,  ..., 3.1871e-01,\n",
      "           3.1871e-01, 1.7125e-01],\n",
      "          [2.9079e-01, 2.9079e-01, 4.7420e-01,  ..., 3.1716e-01,\n",
      "           3.1716e-01, 2.3402e-01],\n",
      "          ...,\n",
      "          [1.2066e-01, 1.8675e-01, 2.7087e-01,  ..., 3.7101e-01,\n",
      "           3.2753e-01, 2.6468e-01],\n",
      "          [1.6196e-01, 4.1850e-01, 2.7513e-01,  ..., 3.8085e-01,\n",
      "           3.1943e-01, 4.6393e-01],\n",
      "          [1.1019e-01, 3.8228e-01, 1.4280e-01,  ..., 3.7663e-01,\n",
      "           2.4051e-01, 2.7890e-01]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 1.1471e-02,  ..., 1.1461e-01,\n",
      "           4.9943e-02, 8.8842e-02],\n",
      "          [4.9921e-02, 4.9921e-02, 6.6809e-02,  ..., 1.7726e-01,\n",
      "           1.7726e-01, 8.8842e-02],\n",
      "          [4.9921e-02, 4.9921e-02, 1.4068e-01,  ..., 1.7726e-01,\n",
      "           1.7726e-01, 3.3514e-01],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 9.3885e-02,  ..., 4.2528e-02,\n",
      "           7.2258e-02, 1.8618e-01],\n",
      "          [2.8572e-02, 2.8572e-02, 9.3885e-02,  ..., 6.3057e-03,\n",
      "           7.2258e-02, 1.8618e-01],\n",
      "          [1.4846e-01, 2.0657e-01, 1.3044e-01,  ..., 9.7375e-02,\n",
      "           1.9152e-01, 1.2392e-01]],\n",
      "\n",
      "         [[2.6535e-01, 3.2553e-01, 4.4228e-01,  ..., 3.7594e-01,\n",
      "           5.2072e-01, 4.1331e-01],\n",
      "          [2.8393e-01, 4.7152e-01, 5.0769e-01,  ..., 4.5346e-01,\n",
      "           5.2072e-01, 3.9886e-01],\n",
      "          [2.9916e-01, 5.4453e-01, 5.4453e-01,  ..., 5.8230e-01,\n",
      "           4.5346e-01, 3.8138e-01],\n",
      "          ...,\n",
      "          [3.2347e-01, 5.7912e-01, 6.2037e-01,  ..., 4.6692e-01,\n",
      "           4.4390e-01, 4.8039e-01],\n",
      "          [4.5314e-01, 5.1741e-01, 5.1741e-01,  ..., 4.6692e-01,\n",
      "           4.4390e-01, 4.6474e-01],\n",
      "          [4.5314e-01, 4.5314e-01, 4.6632e-01,  ..., 4.1781e-01,\n",
      "           5.9588e-01, 5.9588e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.3167e-02,\n",
      "           2.3167e-02, 5.1505e-02],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.3167e-02,\n",
      "           2.3167e-02, 5.1505e-02],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           6.3877e-02, 6.3877e-02],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 8.9262e-02,\n",
      "           7.7988e-02, 8.9712e-02]],\n",
      "\n",
      "         [[1.2420e-01, 1.4079e-01, 1.4079e-01,  ..., 2.5609e-01,\n",
      "           2.5609e-01, 1.8909e-01],\n",
      "          [2.4610e-01, 2.5766e-01, 2.5766e-01,  ..., 2.5609e-01,\n",
      "           2.7493e-01, 2.0960e-01],\n",
      "          [2.4610e-01, 2.0366e-01, 3.2355e-01,  ..., 3.3189e-01,\n",
      "           2.9147e-01, 3.3728e-01],\n",
      "          ...,\n",
      "          [1.5258e-01, 1.7841e-01, 3.8180e-01,  ..., 2.4100e-01,\n",
      "           3.2291e-01, 3.9021e-01],\n",
      "          [1.5258e-01, 2.5047e-01, 2.8323e-01,  ..., 2.4100e-01,\n",
      "           2.2444e-01, 1.4903e-01],\n",
      "          [1.8974e-01, 3.1249e-01, 3.1249e-01,  ..., 4.1969e-01,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           1.4903e-01, 2.9819e-01]]]], grad_fn=<MaxPool2DWithIndicesBackward>)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "output shape:  torch.Size([16, 64, 24, 24])\n",
      "Sequential(\n",
      "  (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (1): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      ")\n",
      "tensor([[[[-7.1130e-02, -7.2006e-02, -9.9349e-02,  ..., -7.4706e-02,\n",
      "           -7.8539e-02, -9.1324e-02],\n",
      "          [-1.3982e-01, -1.7842e-01, -2.0458e-01,  ..., -2.2202e-01,\n",
      "           -2.1171e-01, -7.2277e-02],\n",
      "          [-1.3982e-01, -1.7842e-01, -2.3198e-01,  ..., -2.2202e-01,\n",
      "           -1.9105e-01, -7.2277e-02],\n",
      "          ...,\n",
      "          [-2.1406e-01, -2.2070e-01, -2.0698e-01,  ..., -1.8562e-01,\n",
      "           -1.8562e-01, -5.7674e-02],\n",
      "          [-2.2424e-01, -2.2113e-01, -2.0974e-01,  ..., -2.2218e-01,\n",
      "           -2.4462e-01, -7.8584e-02],\n",
      "          [-1.4444e-01, -1.4136e-01, -1.2401e-01,  ..., -1.5109e-01,\n",
      "           -1.3519e-01, -7.9055e-02]],\n",
      "\n",
      "         [[-5.3434e-02, -9.8641e-02, -1.0723e-01,  ..., -9.2785e-02,\n",
      "           -8.5930e-02, -8.5930e-02],\n",
      "          [-1.6865e-01, -1.6411e-01, -1.6411e-01,  ..., -1.6978e-01,\n",
      "           -1.3383e-01, -1.3383e-01],\n",
      "          [-1.8288e-01, -1.8085e-01, -1.9018e-01,  ..., -1.6803e-01,\n",
      "           -1.6107e-01, -1.3915e-01],\n",
      "          ...,\n",
      "          [-1.7935e-01, -1.4472e-01, -1.4266e-01,  ..., -1.5502e-01,\n",
      "           -1.6825e-01, -1.1449e-01],\n",
      "          [-1.7935e-01, -1.2195e-01, -1.5739e-01,  ..., -1.4594e-01,\n",
      "           -1.9247e-01, -1.1823e-01],\n",
      "          [-1.5249e-01, -1.2195e-01, -1.4774e-01,  ..., -1.4594e-01,\n",
      "           -1.6496e-01, -1.1216e-01]],\n",
      "\n",
      "         [[ 1.2208e-01,  1.2208e-01,  1.2519e-01,  ...,  1.2001e-01,\n",
      "            1.2164e-01,  1.2861e-01],\n",
      "          [ 1.8462e-01,  1.8462e-01,  1.5077e-01,  ...,  1.5389e-01,\n",
      "            1.3579e-01,  1.5503e-01],\n",
      "          [ 1.8462e-01,  1.8462e-01,  1.6117e-01,  ...,  1.5755e-01,\n",
      "            1.5755e-01,  1.5503e-01],\n",
      "          ...,\n",
      "          [ 2.1062e-01,  1.5709e-01,  1.3973e-01,  ...,  1.6101e-01,\n",
      "            1.5194e-01,  1.5194e-01],\n",
      "          [ 1.8099e-01,  1.3074e-01,  1.3180e-01,  ...,  1.4416e-01,\n",
      "            1.5483e-01,  1.6558e-01],\n",
      "          [ 1.8099e-01,  1.2321e-01,  1.1791e-01,  ...,  1.3141e-01,\n",
      "            1.8296e-01,  1.8296e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0535e-01,  8.6282e-02,  1.4002e-01,  ...,  7.3451e-02,\n",
      "            9.2381e-02,  8.0133e-02],\n",
      "          [ 1.3508e-01,  8.6282e-02,  1.4002e-01,  ...,  1.3954e-01,\n",
      "            1.3954e-01,  1.5046e-01],\n",
      "          [ 1.2857e-01,  1.2386e-01,  1.2083e-01,  ...,  1.3954e-01,\n",
      "            1.3954e-01,  1.5046e-01],\n",
      "          ...,\n",
      "          [ 1.1415e-01,  1.1415e-01,  9.1987e-02,  ...,  1.1328e-01,\n",
      "            1.0018e-01,  1.0018e-01],\n",
      "          [ 1.4354e-01,  1.4354e-01,  9.4118e-02,  ...,  1.1328e-01,\n",
      "            1.0813e-01,  1.0813e-01],\n",
      "          [ 1.4354e-01,  1.4354e-01,  8.2478e-02,  ...,  1.1086e-01,\n",
      "            1.1703e-01,  1.1039e-01]],\n",
      "\n",
      "         [[-3.1902e-02, -3.9617e-02, -6.2340e-02,  ..., -7.2377e-02,\n",
      "           -7.2534e-02, -1.0061e-01],\n",
      "          [-2.7733e-02, -3.9617e-02, -5.9213e-02,  ..., -7.2377e-02,\n",
      "           -7.2534e-02, -4.9189e-02],\n",
      "          [-1.5614e-02, -5.3476e-02, -6.3962e-02,  ..., -4.6053e-02,\n",
      "           -7.7011e-02, -7.3840e-02],\n",
      "          ...,\n",
      "          [-1.7074e-02, -7.0979e-02, -6.7683e-02,  ..., -1.0314e-01,\n",
      "           -7.0492e-02, -6.9218e-02],\n",
      "          [-1.9596e-02, -4.6202e-02, -3.8146e-02,  ..., -1.0001e-01,\n",
      "           -6.5890e-02, -5.9335e-02],\n",
      "          [ 1.4632e-02,  1.8349e-02,  3.7715e-02,  ...,  3.3733e-02,\n",
      "            3.3733e-02,  7.5531e-02]],\n",
      "\n",
      "         [[-3.7713e-03, -3.7713e-03, -2.7660e-02,  ..., -9.6712e-04,\n",
      "            1.2949e-02,  6.0864e-02],\n",
      "          [-3.7713e-03, -3.3356e-03,  1.7665e-02,  ..., -9.6712e-04,\n",
      "            1.2949e-02,  6.4764e-02],\n",
      "          [ 2.5940e-02,  2.5940e-02,  8.4856e-03,  ..., -1.9024e-02,\n",
      "            5.9624e-03,  6.7128e-02],\n",
      "          ...,\n",
      "          [ 5.4146e-03,  8.7090e-03,  8.7090e-03,  ..., -1.1468e-02,\n",
      "           -1.3281e-02,  6.2008e-02],\n",
      "          [ 3.1581e-02,  3.1581e-02,  9.6633e-03,  ...,  1.5631e-03,\n",
      "           -7.0038e-03,  1.1619e-01],\n",
      "          [ 3.1581e-02,  3.1581e-02,  9.7692e-03,  ...,  2.6665e-02,\n",
      "           -1.3989e-02,  1.1619e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.4382e-02, -2.4382e-02, -3.8724e-02,  ..., -1.1196e-01,\n",
      "           -1.0696e-01, -6.4679e-02],\n",
      "          [-1.8410e-01, -1.9636e-01, -2.0506e-01,  ..., -2.4384e-01,\n",
      "           -1.9175e-01, -9.1105e-02],\n",
      "          [-1.8410e-01, -2.1106e-01, -1.8437e-01,  ..., -2.4384e-01,\n",
      "           -2.3194e-01, -8.2394e-02],\n",
      "          ...,\n",
      "          [-1.8261e-01, -2.0418e-01, -2.0351e-01,  ..., -2.3727e-01,\n",
      "           -2.2124e-01, -4.0651e-02],\n",
      "          [-1.8369e-01, -2.1122e-01, -2.2343e-01,  ..., -2.1605e-01,\n",
      "           -2.1605e-01, -8.1986e-02],\n",
      "          [-1.4561e-01, -1.5339e-01, -1.2169e-01,  ..., -1.1639e-01,\n",
      "           -1.1639e-01, -9.2109e-02]],\n",
      "\n",
      "         [[-6.4536e-02, -8.7231e-02, -8.5653e-02,  ..., -9.2353e-02,\n",
      "           -1.0551e-01, -8.0693e-02],\n",
      "          [-1.7515e-01, -1.7209e-01, -1.8324e-01,  ..., -1.6768e-01,\n",
      "           -1.6603e-01, -1.3913e-01],\n",
      "          [-1.8248e-01, -1.6395e-01, -1.7552e-01,  ..., -1.6768e-01,\n",
      "           -1.6147e-01, -1.3913e-01],\n",
      "          ...,\n",
      "          [-1.8012e-01, -1.8057e-01, -1.7019e-01,  ..., -1.7509e-01,\n",
      "           -1.6154e-01, -1.3101e-01],\n",
      "          [-1.7648e-01, -1.7166e-01, -1.7166e-01,  ..., -1.6479e-01,\n",
      "           -1.6154e-01, -1.5031e-01],\n",
      "          [-1.3791e-01, -1.3791e-01, -1.5792e-01,  ..., -1.6464e-01,\n",
      "           -1.6077e-01, -1.3984e-01]],\n",
      "\n",
      "         [[ 1.3999e-01,  1.0683e-01,  1.1073e-01,  ...,  1.3898e-01,\n",
      "            1.3898e-01,  1.0562e-01],\n",
      "          [ 1.6430e-01,  1.5680e-01,  1.2599e-01,  ...,  1.3032e-01,\n",
      "            1.4589e-01,  1.4589e-01],\n",
      "          [ 1.7739e-01,  1.5452e-01,  1.6533e-01,  ...,  1.6392e-01,\n",
      "            1.4589e-01,  1.4589e-01],\n",
      "          ...,\n",
      "          [ 1.8360e-01,  1.4084e-01,  1.4084e-01,  ...,  1.4326e-01,\n",
      "            1.6145e-01,  1.8691e-01],\n",
      "          [ 1.8360e-01,  1.7676e-01,  1.4084e-01,  ...,  1.4835e-01,\n",
      "            1.6228e-01,  1.8691e-01],\n",
      "          [ 1.5887e-01,  1.2638e-01,  1.4494e-01,  ...,  1.2104e-01,\n",
      "            1.6228e-01,  1.6228e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.6429e-02,  7.3875e-02,  9.7727e-02,  ...,  9.0431e-02,\n",
      "            9.1817e-02,  1.1748e-01],\n",
      "          [ 1.0443e-01,  1.3348e-01,  1.3348e-01,  ...,  1.5531e-01,\n",
      "            1.7237e-01,  1.7237e-01],\n",
      "          [ 1.0443e-01,  1.3348e-01,  1.3348e-01,  ...,  1.3084e-01,\n",
      "            9.8636e-02,  1.2343e-01],\n",
      "          ...,\n",
      "          [ 1.1332e-01,  1.1332e-01,  1.2058e-01,  ...,  1.1602e-01,\n",
      "            1.1006e-01,  1.1528e-01],\n",
      "          [ 9.4733e-02,  9.0999e-02,  1.3497e-01,  ...,  9.2841e-02,\n",
      "            8.5336e-02,  1.1528e-01],\n",
      "          [ 1.0026e-01,  9.0829e-02,  1.1339e-01,  ...,  9.2107e-02,\n",
      "            9.2459e-02,  9.2459e-02]],\n",
      "\n",
      "         [[-5.0887e-02, -8.5094e-02, -7.7648e-02,  ..., -6.7101e-02,\n",
      "           -3.8605e-02, -6.3172e-02],\n",
      "          [-3.5057e-02, -2.2574e-02, -7.2861e-02,  ..., -5.9636e-02,\n",
      "           -3.8605e-02, -5.6740e-02],\n",
      "          [ 1.5121e-02, -7.1695e-02, -7.1999e-02,  ..., -5.4178e-02,\n",
      "           -6.0500e-02, -5.6740e-02],\n",
      "          ...,\n",
      "          [-4.4330e-02, -8.1563e-02, -7.0593e-02,  ..., -6.5406e-02,\n",
      "           -6.1806e-02, -5.2175e-02],\n",
      "          [-5.7333e-02, -5.2217e-02, -2.4973e-02,  ..., -7.7440e-02,\n",
      "           -6.1806e-02, -2.8642e-02],\n",
      "          [-3.5812e-02,  4.4774e-02,  3.8924e-02,  ...,  1.7221e-02,\n",
      "            1.7221e-02,  7.9838e-02]],\n",
      "\n",
      "         [[-4.0527e-03, -4.0527e-03, -4.8255e-02,  ...,  1.2210e-02,\n",
      "            1.2210e-02,  7.4279e-02],\n",
      "          [-4.0527e-03, -4.0527e-03, -2.1047e-02,  ...,  1.2210e-02,\n",
      "            1.2210e-02,  7.4279e-02],\n",
      "          [-2.0207e-02,  7.7589e-03, -1.2008e-02,  ...,  2.6935e-03,\n",
      "            1.9432e-02,  6.8862e-02],\n",
      "          ...,\n",
      "          [-1.7459e-02, -1.7459e-02, -3.4810e-02,  ...,  1.4243e-02,\n",
      "            7.2551e-03,  1.0585e-01],\n",
      "          [ 4.5431e-03,  4.5431e-03,  6.3466e-02,  ..., -4.0185e-03,\n",
      "            2.7651e-03,  1.1326e-01],\n",
      "          [ 5.2106e-02,  5.2106e-02,  9.5130e-03,  ..., -4.1793e-03,\n",
      "           -4.1793e-03,  1.1326e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.2996e-02, -4.9226e-02, -9.9618e-02,  ..., -8.9323e-02,\n",
      "           -1.9621e-02, -6.0464e-02],\n",
      "          [-1.5745e-01, -1.5745e-01, -2.4771e-01,  ..., -2.1385e-01,\n",
      "           -2.2041e-01, -8.1563e-02],\n",
      "          [-1.8234e-01, -2.4286e-01, -2.4286e-01,  ..., -2.1132e-01,\n",
      "           -2.1132e-01, -8.1563e-02],\n",
      "          ...,\n",
      "          [-1.8622e-01, -1.8622e-01, -2.0192e-01,  ..., -2.1235e-01,\n",
      "           -2.1235e-01, -8.8303e-02],\n",
      "          [-1.7125e-01, -2.1015e-01, -2.1015e-01,  ..., -2.1113e-01,\n",
      "           -2.1113e-01, -6.6624e-02],\n",
      "          [-1.3205e-01, -1.2258e-01, -1.1387e-01,  ..., -1.4335e-01,\n",
      "           -9.3478e-02, -6.6624e-02]],\n",
      "\n",
      "         [[-7.0101e-02, -8.3615e-02, -1.0837e-01,  ..., -7.5599e-02,\n",
      "           -8.5034e-02, -6.4091e-02],\n",
      "          [-1.5522e-01, -1.4788e-01, -1.4788e-01,  ..., -9.8776e-02,\n",
      "           -1.6464e-01, -1.6669e-01],\n",
      "          [-1.9753e-01, -1.8620e-01, -1.6502e-01,  ..., -1.6461e-01,\n",
      "           -1.5060e-01, -1.5602e-01],\n",
      "          ...,\n",
      "          [-1.7677e-01, -1.6620e-01, -1.6620e-01,  ..., -1.6860e-01,\n",
      "           -1.7251e-01, -1.3129e-01],\n",
      "          [-1.8126e-01, -1.6105e-01, -1.6105e-01,  ..., -1.6860e-01,\n",
      "           -1.6832e-01, -1.3129e-01],\n",
      "          [-1.7912e-01, -1.5376e-01, -1.5020e-01,  ..., -1.7640e-01,\n",
      "           -1.6832e-01, -1.6446e-01]],\n",
      "\n",
      "         [[ 1.6292e-01,  1.3848e-01,  1.3848e-01,  ...,  1.0743e-01,\n",
      "            1.1250e-01,  1.3076e-01],\n",
      "          [ 1.6292e-01,  1.1096e-01,  1.1795e-01,  ...,  1.2764e-01,\n",
      "            1.4199e-01,  1.7878e-01],\n",
      "          [ 1.5285e-01,  1.5285e-01,  1.4186e-01,  ...,  1.4937e-01,\n",
      "            1.5932e-01,  1.7878e-01],\n",
      "          ...,\n",
      "          [ 1.6029e-01,  1.4323e-01,  1.2616e-01,  ...,  1.7470e-01,\n",
      "            1.5291e-01,  1.7520e-01],\n",
      "          [ 2.1098e-01,  1.7345e-01,  1.8318e-01,  ...,  1.7683e-01,\n",
      "            1.6549e-01,  1.7520e-01],\n",
      "          [ 2.2574e-01,  2.2574e-01,  1.5075e-01,  ...,  1.8864e-01,\n",
      "            1.6549e-01,  1.6549e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0751e-01,  9.2312e-02,  7.2361e-02,  ...,  8.0430e-02,\n",
      "            1.0097e-01,  1.1055e-01],\n",
      "          [ 1.2032e-01,  1.2032e-01,  1.0759e-01,  ...,  1.3110e-01,\n",
      "            1.3110e-01,  1.1055e-01],\n",
      "          [ 1.5225e-01,  1.2032e-01,  1.0759e-01,  ...,  1.3110e-01,\n",
      "            1.3110e-01,  9.7146e-02],\n",
      "          ...,\n",
      "          [ 1.3178e-01,  1.0321e-01,  1.1782e-01,  ...,  1.3085e-01,\n",
      "            1.3327e-01,  1.2886e-01],\n",
      "          [ 1.3239e-01,  1.4483e-01,  1.4483e-01,  ...,  1.3085e-01,\n",
      "            1.2021e-01,  1.1222e-01],\n",
      "          [ 1.3867e-01,  1.4483e-01,  1.4483e-01,  ...,  8.6130e-02,\n",
      "            1.1346e-01,  1.1346e-01]],\n",
      "\n",
      "         [[-1.0912e-02, -6.0094e-02, -5.8043e-02,  ..., -8.6798e-02,\n",
      "           -9.9666e-02, -6.9283e-02],\n",
      "          [-1.0912e-02, -6.0094e-02, -5.8043e-02,  ..., -8.6798e-02,\n",
      "           -6.5117e-02, -4.8368e-02],\n",
      "          [-3.6281e-02, -3.3950e-02, -7.2794e-02,  ..., -5.3719e-02,\n",
      "           -6.5117e-02, -4.8368e-02],\n",
      "          ...,\n",
      "          [-3.2600e-02, -7.0647e-02, -4.4829e-02,  ..., -7.5382e-02,\n",
      "           -8.7685e-02, -4.2942e-02],\n",
      "          [-4.7702e-02, -7.0647e-02, -6.0076e-02,  ..., -6.5487e-02,\n",
      "           -6.5487e-02, -4.8539e-02],\n",
      "          [ 3.6650e-02,  3.6650e-02,  2.2355e-02,  ...,  4.7217e-02,\n",
      "            1.9754e-02,  8.8465e-02]],\n",
      "\n",
      "         [[-3.4540e-02, -3.4540e-02, -8.0971e-04,  ..., -9.9359e-03,\n",
      "           -9.9359e-03,  7.4820e-02],\n",
      "          [-2.6127e-02,  1.2792e-02,  1.2792e-02,  ..., -9.9359e-03,\n",
      "           -9.9359e-03,  8.4166e-02],\n",
      "          [ 3.3584e-02,  3.3584e-02,  1.2792e-02,  ..., -1.5334e-02,\n",
      "           -1.5334e-02,  8.4166e-02],\n",
      "          ...,\n",
      "          [ 3.8001e-02,  3.8001e-02, -1.8657e-02,  ...,  1.1955e-03,\n",
      "           -2.1972e-02,  1.0638e-01],\n",
      "          [-1.1969e-02, -1.0105e-02, -5.0688e-03,  ...,  1.1955e-03,\n",
      "           -9.1865e-03,  1.0638e-01],\n",
      "          [-5.1410e-03, -5.1410e-03, -5.0688e-03,  ...,  7.2665e-03,\n",
      "            7.2665e-03,  7.9066e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-5.4264e-02, -9.8010e-02, -9.3119e-02,  ..., -1.1056e-01,\n",
      "           -8.3567e-02, -3.0952e-02],\n",
      "          [-1.9670e-01, -1.9670e-01, -2.1170e-01,  ..., -1.9439e-01,\n",
      "           -2.3890e-01, -7.4359e-02],\n",
      "          [-1.9670e-01, -1.9670e-01, -2.2839e-01,  ..., -2.1491e-01,\n",
      "           -2.4195e-01, -1.0894e-01],\n",
      "          ...,\n",
      "          [-1.5908e-01, -2.1725e-01, -2.0745e-01,  ..., -2.3894e-01,\n",
      "           -2.0610e-01, -1.8415e-02],\n",
      "          [-2.0244e-01, -2.1881e-01, -2.2088e-01,  ..., -2.5609e-01,\n",
      "           -2.2694e-01, -1.8415e-02],\n",
      "          [-1.4221e-01, -1.6415e-01, -1.3231e-01,  ..., -9.7274e-02,\n",
      "           -1.1441e-01, -6.0341e-02]],\n",
      "\n",
      "         [[-3.2561e-02, -8.2872e-02, -8.2872e-02,  ..., -6.2487e-02,\n",
      "           -6.2487e-02, -5.2339e-02],\n",
      "          [-2.0408e-01, -1.7990e-01, -1.6798e-01,  ..., -1.5987e-01,\n",
      "           -1.5492e-01, -1.5492e-01],\n",
      "          [-2.1176e-01, -1.9269e-01, -1.6798e-01,  ..., -1.6218e-01,\n",
      "           -1.6588e-01, -1.3801e-01],\n",
      "          ...,\n",
      "          [-1.7318e-01, -1.5702e-01, -1.5596e-01,  ..., -1.5786e-01,\n",
      "           -1.4987e-01, -1.4396e-01],\n",
      "          [-1.4908e-01, -1.7193e-01, -1.5660e-01,  ..., -1.5089e-01,\n",
      "           -1.4987e-01, -1.4396e-01],\n",
      "          [-1.3857e-01, -1.5086e-01, -1.6196e-01,  ..., -1.6248e-01,\n",
      "           -1.6056e-01, -1.4916e-01]],\n",
      "\n",
      "         [[ 1.2394e-01,  1.2346e-01,  1.3594e-01,  ...,  1.3785e-01,\n",
      "            1.2562e-01,  1.3498e-01],\n",
      "          [ 1.8623e-01,  1.3148e-01,  1.1931e-01,  ...,  1.4574e-01,\n",
      "            1.4574e-01,  1.3498e-01],\n",
      "          [ 1.8623e-01,  1.3862e-01,  1.3793e-01,  ...,  1.4496e-01,\n",
      "            1.7545e-01,  2.0328e-01],\n",
      "          ...,\n",
      "          [ 1.9626e-01,  1.5372e-01,  1.7262e-01,  ...,  1.4926e-01,\n",
      "            1.9603e-01,  1.9603e-01],\n",
      "          [ 1.9626e-01,  1.5372e-01,  1.7262e-01,  ...,  1.3905e-01,\n",
      "            1.9204e-01,  1.6181e-01],\n",
      "          [ 1.8699e-01,  1.5198e-01,  1.5308e-01,  ...,  1.6095e-01,\n",
      "            1.9204e-01,  1.8223e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1827e-01,  1.1827e-01,  1.3809e-01,  ...,  1.2689e-01,\n",
      "            9.6830e-02,  8.7303e-02],\n",
      "          [ 1.6771e-01,  1.6771e-01,  1.5212e-01,  ...,  1.2689e-01,\n",
      "            1.0856e-01,  1.5353e-01],\n",
      "          [ 1.5039e-01,  1.5039e-01,  1.5212e-01,  ...,  1.2173e-01,\n",
      "            1.2173e-01,  1.2751e-01],\n",
      "          ...,\n",
      "          [ 1.1416e-01,  1.0962e-01,  1.3336e-01,  ...,  1.0926e-01,\n",
      "            1.1342e-01,  1.2050e-01],\n",
      "          [ 1.2120e-01,  9.7636e-02,  1.1895e-01,  ...,  1.3783e-01,\n",
      "            1.3783e-01,  1.2050e-01],\n",
      "          [ 1.2120e-01,  9.7636e-02,  1.1220e-01,  ...,  9.1834e-02,\n",
      "            1.1902e-01,  1.1902e-01]],\n",
      "\n",
      "         [[-5.1986e-02, -7.1585e-02, -7.1585e-02,  ..., -5.1707e-02,\n",
      "           -7.8298e-02, -5.3339e-02],\n",
      "          [-4.6347e-02, -7.1585e-02, -7.1585e-02,  ..., -1.0461e-02,\n",
      "           -5.1719e-02, -5.1719e-02],\n",
      "          [-4.3975e-03, -6.9092e-02, -8.0555e-02,  ..., -5.6705e-02,\n",
      "           -4.4194e-02, -5.1719e-02],\n",
      "          ...,\n",
      "          [ 2.5621e-02, -3.1996e-02, -3.1996e-02,  ..., -5.8161e-02,\n",
      "           -5.8161e-02, -7.2360e-02],\n",
      "          [-3.0788e-02, -6.1070e-02, -6.1070e-02,  ..., -4.3772e-02,\n",
      "           -6.2776e-02, -7.8658e-02],\n",
      "          [ 3.0632e-02,  3.0632e-02,  2.4391e-02,  ...,  2.5625e-02,\n",
      "            5.8662e-02,  9.0568e-02]],\n",
      "\n",
      "         [[ 4.4133e-02,  4.4133e-02,  6.4264e-03,  ..., -2.1310e-02,\n",
      "           -1.2475e-02,  7.0175e-02],\n",
      "          [ 4.4133e-02,  4.4133e-02,  6.4264e-03,  ...,  1.4210e-02,\n",
      "           -1.2475e-02,  1.0906e-01],\n",
      "          [ 4.2331e-03,  4.2331e-03,  8.2003e-03,  ...,  1.4210e-02,\n",
      "           -5.0914e-02,  1.0809e-01],\n",
      "          ...,\n",
      "          [-1.7631e-03, -2.4579e-04,  6.5994e-03,  ...,  1.1940e-02,\n",
      "            1.1940e-02,  8.4817e-02],\n",
      "          [-7.2856e-03,  2.4477e-02, -2.1230e-02,  ..., -1.7600e-03,\n",
      "           -6.2412e-03,  7.9999e-02],\n",
      "          [ 4.6969e-02,  4.6969e-02, -2.1230e-02,  ...,  1.1453e-02,\n",
      "            1.0721e-02,  7.9999e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.9698e-02, -6.3705e-02, -4.5884e-02,  ..., -9.0498e-02,\n",
      "           -1.0854e-01, -6.8115e-02],\n",
      "          [-1.6301e-01, -1.9050e-01, -2.3164e-01,  ..., -2.3061e-01,\n",
      "           -2.0873e-01, -9.8054e-02],\n",
      "          [-2.0214e-01, -2.0738e-01, -2.2586e-01,  ..., -2.3002e-01,\n",
      "           -2.3002e-01, -4.4653e-02],\n",
      "          ...,\n",
      "          [-1.3746e-01, -2.1859e-01, -2.0688e-01,  ..., -2.2842e-01,\n",
      "           -2.2821e-01, -4.8192e-02],\n",
      "          [-1.3746e-01, -1.8736e-01, -2.7645e-01,  ..., -2.2842e-01,\n",
      "           -2.2821e-01, -1.0869e-01],\n",
      "          [-1.2795e-01, -1.2036e-01, -1.7540e-01,  ..., -1.1315e-01,\n",
      "           -1.1221e-01, -6.2616e-02]],\n",
      "\n",
      "         [[-5.5284e-02, -6.7016e-02, -9.1757e-02,  ..., -1.0148e-01,\n",
      "           -8.4203e-02, -8.4203e-02],\n",
      "          [-1.8302e-01, -1.5889e-01, -1.6253e-01,  ..., -1.6635e-01,\n",
      "           -1.6635e-01, -1.4510e-01],\n",
      "          [-1.8885e-01, -1.5889e-01, -1.4404e-01,  ..., -1.7669e-01,\n",
      "           -1.4782e-01, -1.1448e-01],\n",
      "          ...,\n",
      "          [-1.7573e-01, -1.6142e-01, -1.5835e-01,  ..., -1.6327e-01,\n",
      "           -1.6327e-01, -1.5761e-01],\n",
      "          [-1.7730e-01, -1.4931e-01, -1.5835e-01,  ..., -1.6301e-01,\n",
      "           -1.6074e-01, -1.4075e-01],\n",
      "          [-1.7706e-01, -1.5390e-01, -1.5959e-01,  ..., -1.6301e-01,\n",
      "           -1.5327e-01, -1.2809e-01]],\n",
      "\n",
      "         [[ 1.3365e-01,  1.0585e-01,  1.3470e-01,  ...,  1.0761e-01,\n",
      "            1.2712e-01,  1.2712e-01],\n",
      "          [ 1.9046e-01,  1.6432e-01,  1.2077e-01,  ...,  1.5273e-01,\n",
      "            1.8031e-01,  1.8031e-01],\n",
      "          [ 1.9046e-01,  1.6432e-01,  1.5404e-01,  ...,  1.3647e-01,\n",
      "            1.6211e-01,  1.7341e-01],\n",
      "          ...,\n",
      "          [ 1.5799e-01,  1.4560e-01,  1.5777e-01,  ...,  1.9159e-01,\n",
      "            1.4820e-01,  1.8090e-01],\n",
      "          [ 1.5809e-01,  1.4560e-01,  1.5777e-01,  ...,  1.5058e-01,\n",
      "            1.5484e-01,  1.6404e-01],\n",
      "          [ 1.5738e-01,  1.6427e-01,  1.6452e-01,  ...,  1.6552e-01,\n",
      "            1.5484e-01,  1.5484e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.7513e-02,  8.3191e-02,  8.3191e-02,  ...,  9.9061e-02,\n",
      "            9.9061e-02,  9.0812e-02],\n",
      "          [ 1.4076e-01,  1.0659e-01,  1.0852e-01,  ...,  1.3374e-01,\n",
      "            9.9061e-02,  1.3483e-01],\n",
      "          [ 1.4076e-01,  1.2236e-01,  1.2624e-01,  ...,  1.3446e-01,\n",
      "            1.0772e-01,  1.0772e-01],\n",
      "          ...,\n",
      "          [ 1.0978e-01,  1.1650e-01,  1.2219e-01,  ...,  1.0716e-01,\n",
      "            1.1403e-01,  1.3156e-01],\n",
      "          [ 1.2539e-01,  1.1650e-01,  1.1563e-01,  ...,  1.2689e-01,\n",
      "            9.7331e-02,  1.3156e-01],\n",
      "          [ 1.3135e-01,  1.2157e-01,  1.0409e-01,  ...,  9.8324e-02,\n",
      "            1.0457e-01,  8.5829e-02]],\n",
      "\n",
      "         [[-7.0579e-02, -7.7644e-02, -7.3551e-02,  ..., -6.1299e-02,\n",
      "           -6.6328e-02, -5.4382e-02],\n",
      "          [-2.0298e-02, -3.1710e-02, -6.2521e-02,  ..., -6.1299e-02,\n",
      "           -4.2931e-02, -3.1358e-02],\n",
      "          [-2.4549e-02, -8.9771e-02, -6.3533e-02,  ..., -5.6147e-02,\n",
      "           -7.9558e-02, -3.1358e-02],\n",
      "          ...,\n",
      "          [-3.1754e-02, -4.7614e-02, -6.7394e-02,  ..., -4.4205e-02,\n",
      "           -7.0210e-02, -2.8005e-02],\n",
      "          [-6.2848e-02, -4.7614e-02, -6.4616e-02,  ..., -4.4205e-02,\n",
      "           -7.0210e-02, -2.8005e-02],\n",
      "          [-2.5618e-02,  8.7252e-03,  1.1609e-02,  ...,  2.4816e-02,\n",
      "            2.4816e-02,  5.7836e-02]],\n",
      "\n",
      "         [[-2.9748e-02, -1.4015e-02, -5.4986e-02,  ..., -3.4681e-02,\n",
      "           -3.2669e-02,  6.6860e-02],\n",
      "          [ 2.5077e-02,  2.5077e-02,  5.4108e-03,  ...,  2.0233e-02,\n",
      "           -3.6257e-03,  6.6860e-02],\n",
      "          [ 3.8778e-02,  3.8778e-02,  1.3415e-02,  ...,  4.4418e-03,\n",
      "            1.6689e-02,  7.4725e-02],\n",
      "          ...,\n",
      "          [-2.9104e-02,  3.7579e-02,  3.7579e-02,  ...,  1.7322e-02,\n",
      "           -1.1467e-03,  1.1290e-01],\n",
      "          [-2.0130e-03,  3.7579e-02,  3.7579e-02,  ...,  1.7935e-02,\n",
      "           -5.1657e-03,  1.3645e-01],\n",
      "          [-1.5186e-04, -1.5186e-04,  1.6604e-02,  ...,  2.7302e-02,\n",
      "           -6.1763e-03,  7.3877e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.5847e-02, -3.9358e-02, -6.8940e-02,  ..., -1.1394e-01,\n",
      "           -1.1394e-01, -4.2206e-02],\n",
      "          [-2.0424e-01, -2.0951e-01, -2.1756e-01,  ..., -2.2677e-01,\n",
      "           -2.2864e-01, -4.2206e-02],\n",
      "          [-2.0096e-01, -1.7762e-01, -1.7762e-01,  ..., -2.2677e-01,\n",
      "           -2.3094e-01, -9.1454e-02],\n",
      "          ...,\n",
      "          [-1.7129e-01, -1.8192e-01, -2.3386e-01,  ..., -2.1327e-01,\n",
      "           -2.0090e-01, -9.7511e-02],\n",
      "          [-1.9997e-01, -2.4135e-01, -2.5343e-01,  ..., -2.3486e-01,\n",
      "           -2.0090e-01, -1.1895e-01],\n",
      "          [-1.2568e-01, -1.2232e-01, -1.2232e-01,  ..., -1.3266e-01,\n",
      "           -9.8314e-02, -8.0517e-02]],\n",
      "\n",
      "         [[-3.8793e-02, -1.0694e-01, -1.0155e-01,  ..., -8.9938e-02,\n",
      "           -8.9938e-02, -9.9936e-02],\n",
      "          [-1.7300e-01, -1.7297e-01, -1.7297e-01,  ..., -1.8787e-01,\n",
      "           -1.7842e-01, -1.5467e-01],\n",
      "          [-1.7300e-01, -1.7297e-01, -1.4912e-01,  ..., -1.4468e-01,\n",
      "           -1.4468e-01, -1.5467e-01],\n",
      "          ...,\n",
      "          [-1.7883e-01, -1.6807e-01, -1.6807e-01,  ..., -1.7638e-01,\n",
      "           -1.5848e-01, -1.4703e-01],\n",
      "          [-1.6181e-01, -1.7047e-01, -1.7047e-01,  ..., -1.8131e-01,\n",
      "           -1.5687e-01, -1.5517e-01],\n",
      "          [-1.6026e-01, -1.7073e-01, -1.5480e-01,  ..., -1.4705e-01,\n",
      "           -1.4705e-01, -1.2358e-01]],\n",
      "\n",
      "         [[ 1.7206e-01,  1.2354e-01,  1.5140e-01,  ...,  1.0324e-01,\n",
      "            1.0363e-01,  1.0637e-01],\n",
      "          [ 1.7618e-01,  1.3142e-01,  1.5140e-01,  ...,  1.3981e-01,\n",
      "            1.4839e-01,  1.7969e-01],\n",
      "          [ 2.1845e-01,  1.3142e-01,  1.3142e-01,  ...,  1.5268e-01,\n",
      "            1.4802e-01,  1.7969e-01],\n",
      "          ...,\n",
      "          [ 1.4359e-01,  1.3037e-01,  1.4094e-01,  ...,  1.4110e-01,\n",
      "            1.4110e-01,  1.6225e-01],\n",
      "          [ 1.4881e-01,  1.2843e-01,  1.4483e-01,  ...,  1.2917e-01,\n",
      "            1.4701e-01,  1.8412e-01],\n",
      "          [ 1.7381e-01,  1.3914e-01,  1.4483e-01,  ...,  1.0648e-01,\n",
      "            1.4701e-01,  1.6609e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.7924e-02,  8.8084e-02,  1.0535e-01,  ...,  1.1378e-01,\n",
      "            1.1378e-01,  1.0460e-01],\n",
      "          [ 1.0607e-01,  1.1315e-01,  1.4636e-01,  ...,  1.2256e-01,\n",
      "            1.3166e-01,  1.1938e-01],\n",
      "          [ 1.1769e-01,  1.1769e-01,  1.2116e-01,  ...,  1.0481e-01,\n",
      "            1.3271e-01,  1.3271e-01],\n",
      "          ...,\n",
      "          [ 1.3747e-01,  1.1282e-01,  1.1705e-01,  ...,  1.3615e-01,\n",
      "            1.3394e-01,  1.4959e-01],\n",
      "          [ 9.9586e-02,  1.2610e-01,  1.1705e-01,  ...,  1.0997e-01,\n",
      "            1.2637e-01,  1.3007e-01],\n",
      "          [ 9.9586e-02,  1.2548e-01,  1.2548e-01,  ...,  1.1372e-01,\n",
      "            8.3745e-02,  1.1258e-01]],\n",
      "\n",
      "         [[ 3.8340e-02, -5.9661e-02, -6.7053e-02,  ..., -4.7676e-02,\n",
      "           -6.1300e-02, -2.1945e-02],\n",
      "          [ 3.8340e-02, -5.1059e-02, -4.1764e-02,  ..., -3.5856e-02,\n",
      "           -3.5856e-02, -2.1945e-02],\n",
      "          [-2.6645e-03, -5.9909e-02, -5.9909e-02,  ..., -5.0313e-02,\n",
      "           -5.0313e-02, -7.0460e-02],\n",
      "          ...,\n",
      "          [-2.3467e-02, -7.2349e-02, -7.7346e-02,  ..., -9.3579e-02,\n",
      "           -7.4154e-02, -1.8130e-02],\n",
      "          [-3.4213e-02, -6.3382e-02, -6.2868e-02,  ..., -6.5454e-02,\n",
      "           -7.3934e-02, -2.9201e-02],\n",
      "          [-2.2939e-02, -1.4541e-02,  1.7154e-02,  ...,  1.8351e-02,\n",
      "            3.3645e-02,  8.0810e-02]],\n",
      "\n",
      "         [[-6.2607e-03, -6.2607e-03, -3.1846e-02,  ..., -2.4280e-02,\n",
      "            8.5358e-05,  5.2623e-02],\n",
      "          [-6.2607e-03,  1.6337e-02, -2.5413e-02,  ..., -3.5099e-02,\n",
      "            2.5784e-03,  6.9029e-02],\n",
      "          [ 2.6561e-02,  2.6561e-02, -2.0945e-02,  ..., -1.0989e-02,\n",
      "           -1.9721e-02,  8.0273e-02],\n",
      "          ...,\n",
      "          [-1.7213e-02, -8.9566e-03,  8.5800e-03,  ...,  1.6961e-02,\n",
      "            1.6961e-02,  8.3966e-02],\n",
      "          [-2.6566e-03,  1.7574e-02,  1.7574e-02,  ..., -1.7211e-02,\n",
      "           -6.2450e-03,  9.8464e-02],\n",
      "          [-7.1186e-03,  1.7574e-02,  2.9701e-02,  ..., -2.6332e-02,\n",
      "           -4.3943e-02,  8.0499e-02]]]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<MaxPool2DWithIndicesBackward>)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "output shape:  torch.Size([16, 192, 12, 12])\n",
      "Sequential(\n",
      "  (0): Inception(\n",
      "    (p1_1): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p2_1): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p2_2): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (p3_1): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p3_2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "    (p4_2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (1): Inception(\n",
      "    (p1_1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p2_1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p2_2): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (p3_1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p3_2): Conv2d(32, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "    (p4_2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      ")\n",
      "tensor([[[[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           5.0307e-03],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           9.3587e-03],\n",
      "          [3.1525e-03, 3.1525e-03, 1.2622e-03, 0.0000e+00, 0.0000e+00,\n",
      "           9.3587e-03],\n",
      "          [3.1525e-03, 3.1525e-03, 1.2622e-03, 0.0000e+00, 0.0000e+00,\n",
      "           5.7737e-03],\n",
      "          [1.7225e-03, 1.7225e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           4.6153e-03],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           1.3661e-02]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[5.7003e-03, 1.8473e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [1.0411e-02, 6.3767e-03, 7.9440e-03, 7.9440e-03, 1.0510e-02,\n",
      "           4.4734e-03],\n",
      "          [1.0411e-02, 9.0835e-03, 1.1854e-02, 1.1854e-02, 1.2249e-02,\n",
      "           5.1313e-03],\n",
      "          [1.0213e-02, 9.5162e-03, 1.1854e-02, 1.2634e-02, 1.2634e-02,\n",
      "           4.6799e-03],\n",
      "          [1.1314e-02, 9.5162e-03, 9.6290e-03, 1.2012e-02, 1.2012e-02,\n",
      "           5.5017e-03],\n",
      "          [9.0476e-03, 5.1713e-03, 5.1713e-03, 5.1929e-03, 8.8518e-03,\n",
      "           2.3324e-03]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4198e-03,\n",
      "           5.7634e-03],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4198e-03,\n",
      "           6.4189e-03],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           5.2975e-03],\n",
      "          [3.1526e-03, 3.1526e-03, 0.0000e+00, 2.6172e-04, 2.6172e-04,\n",
      "           1.0032e-02],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3158e-03, 1.4913e-03,\n",
      "           5.3480e-03],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3158e-03, 0.0000e+00,\n",
      "           1.3447e-02]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[3.5551e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [1.2302e-02, 1.1319e-02, 1.1319e-02, 9.4924e-03, 8.5758e-03,\n",
      "           3.1330e-03],\n",
      "          [1.2302e-02, 1.1319e-02, 1.1319e-02, 9.4924e-03, 8.5758e-03,\n",
      "           3.1330e-03],\n",
      "          [1.4611e-02, 1.0145e-02, 7.9905e-03, 7.6661e-03, 7.7985e-03,\n",
      "           1.6489e-03],\n",
      "          [1.4611e-02, 1.0145e-02, 8.7635e-03, 1.1006e-02, 1.1006e-02,\n",
      "           8.2004e-04],\n",
      "          [1.3104e-02, 1.3103e-02, 1.3103e-02, 7.1445e-03, 7.7202e-03,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[3.7636e-04, 3.7636e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           5.4841e-03],\n",
      "          [3.7636e-04, 3.7636e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           5.4841e-03],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           6.7163e-03],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           6.7163e-03],\n",
      "          [2.8912e-05, 4.2636e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           4.5465e-03],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           1.0759e-02]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[5.1286e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [6.3377e-03, 5.3917e-03, 9.1447e-03, 9.1447e-03, 9.5558e-03,\n",
      "           3.4273e-03],\n",
      "          [1.0637e-02, 7.0855e-03, 1.0976e-02, 1.0976e-02, 9.5558e-03,\n",
      "           4.6481e-03],\n",
      "          [1.1144e-02, 7.3635e-03, 7.5450e-03, 8.1744e-03, 8.3119e-03,\n",
      "           7.2338e-03],\n",
      "          [8.2967e-03, 7.3303e-03, 7.3303e-03, 1.0705e-02, 1.0705e-02,\n",
      "           6.1765e-03],\n",
      "          [1.2140e-02, 6.1107e-03, 8.2170e-03, 8.2170e-03, 7.8229e-03,\n",
      "           1.8059e-03]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0000e+00, 0.0000e+00, 1.6614e-03, 0.0000e+00, 6.0890e-05,\n",
      "           8.3288e-03],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.0890e-05,\n",
      "           1.4661e-02],\n",
      "          [1.0673e-03, 1.6262e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           1.0038e-02],\n",
      "          [1.0673e-03, 1.6262e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           8.9036e-03],\n",
      "          [1.0960e-03, 1.0960e-03, 0.0000e+00, 5.0228e-05, 5.0228e-05,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0228e-05, 5.0228e-05,\n",
      "           1.0544e-02]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[4.6572e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [1.1216e-02, 8.1050e-03, 8.1050e-03, 7.4591e-03, 8.0602e-03,\n",
      "           0.0000e+00],\n",
      "          [1.1216e-02, 1.0884e-02, 1.0884e-02, 1.3540e-02, 1.3540e-02,\n",
      "           9.7792e-04],\n",
      "          [8.2864e-03, 7.5507e-03, 1.0535e-02, 1.3540e-02, 1.3540e-02,\n",
      "           2.7682e-03],\n",
      "          [1.0526e-02, 8.9674e-03, 9.3635e-03, 8.5135e-03, 9.6151e-03,\n",
      "           3.0590e-03],\n",
      "          [1.3901e-02, 7.7046e-03, 4.6820e-03, 2.3821e-03, 1.1835e-03,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[0.0000e+00, 7.3683e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           4.4446e-03],\n",
      "          [0.0000e+00, 7.3683e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           5.5333e-03],\n",
      "          [1.4669e-03, 1.4669e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           5.5333e-03],\n",
      "          [1.7551e-03, 1.7551e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           5.8642e-03],\n",
      "          [1.7551e-03, 1.7551e-03, 2.2031e-03, 2.2031e-03, 0.0000e+00,\n",
      "           7.0638e-03],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           1.5095e-02]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[6.5496e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [1.1851e-02, 7.5100e-03, 1.0165e-02, 1.0165e-02, 5.8124e-03,\n",
      "           5.6976e-03],\n",
      "          [1.1851e-02, 9.7152e-03, 1.0165e-02, 1.0165e-02, 7.0046e-03,\n",
      "           5.6976e-03],\n",
      "          [1.1378e-02, 1.1104e-02, 1.1207e-02, 1.0121e-02, 1.0652e-02,\n",
      "           5.9298e-03],\n",
      "          [9.8992e-03, 8.3611e-03, 8.3611e-03, 1.0121e-02, 1.1524e-02,\n",
      "           4.6605e-03],\n",
      "          [1.0251e-02, 7.7183e-03, 7.7183e-03, 6.5348e-03, 4.6069e-03,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[3.7750e-03, 3.7750e-03, 0.0000e+00, 2.2122e-03, 1.3502e-03,\n",
      "           0.0000e+00],\n",
      "          [3.7750e-03, 3.7750e-03, 0.0000e+00, 2.2122e-03, 1.3502e-03,\n",
      "           4.7207e-03],\n",
      "          [1.9911e-03, 1.9911e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           1.1420e-02],\n",
      "          [7.1117e-04, 7.1117e-04, 2.1944e-03, 0.0000e+00, 0.0000e+00,\n",
      "           1.1420e-02],\n",
      "          [2.8739e-03, 2.8739e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           7.3306e-03],\n",
      "          [2.8739e-03, 2.8739e-03, 2.8378e-03, 0.0000e+00, 0.0000e+00,\n",
      "           1.1480e-02]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[3.8866e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [1.4119e-02, 1.0498e-02, 1.1069e-02, 1.1069e-02, 7.4460e-03,\n",
      "           7.0244e-04],\n",
      "          [1.4297e-02, 1.0498e-02, 1.1265e-02, 1.1265e-02, 9.5529e-03,\n",
      "           2.7512e-03],\n",
      "          [1.4756e-02, 1.0088e-02, 1.0104e-02, 1.0104e-02, 9.0578e-03,\n",
      "           2.7512e-03],\n",
      "          [1.4449e-02, 1.1105e-02, 1.3064e-02, 1.3064e-02, 8.9020e-03,\n",
      "           5.1701e-03],\n",
      "          [1.1676e-02, 9.9859e-03, 9.9859e-03, 9.4866e-03, 7.5454e-03,\n",
      "           3.7306e-03]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0.0000e+00]]]], grad_fn=<MaxPool2DWithIndicesBackward>)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "output shape:  torch.Size([16, 480, 6, 6])\n",
      "Sequential(\n",
      "  (0): Inception(\n",
      "    (p1_1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p2_1): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p2_2): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (p3_1): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p3_2): Conv2d(16, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "    (p4_2): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (1): Inception(\n",
      "    (p1_1): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p2_1): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p2_2): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (p3_1): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p3_2): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "    (p4_2): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (2): Inception(\n",
      "    (p1_1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p2_1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p2_2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (p3_1): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p3_2): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "    (p4_2): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (3): Inception(\n",
      "    (p1_1): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p2_1): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p2_2): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (p3_1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p3_2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "    (p4_2): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (4): Inception(\n",
      "    (p1_1): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p2_1): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p2_2): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (p3_1): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p3_2): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "    (p4_2): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (5): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      ")\n",
      "tensor([[[[0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0311, 0.0312, 0.0312],\n",
      "          [0.0306, 0.0315, 0.0316],\n",
      "          [0.0328, 0.0337, 0.0337]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0245, 0.0247, 0.0244],\n",
      "          [0.0245, 0.0248, 0.0248],\n",
      "          [0.0242, 0.0251, 0.0251]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0311, 0.0312, 0.0312],\n",
      "          [0.0306, 0.0315, 0.0316],\n",
      "          [0.0328, 0.0337, 0.0337]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0245, 0.0247, 0.0244],\n",
      "          [0.0245, 0.0248, 0.0248],\n",
      "          [0.0242, 0.0251, 0.0251]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0311, 0.0312, 0.0312],\n",
      "          [0.0306, 0.0315, 0.0316],\n",
      "          [0.0328, 0.0337, 0.0337]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0245, 0.0247, 0.0244],\n",
      "          [0.0245, 0.0248, 0.0248],\n",
      "          [0.0242, 0.0251, 0.0251]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0311, 0.0312, 0.0312],\n",
      "          [0.0306, 0.0315, 0.0316],\n",
      "          [0.0328, 0.0337, 0.0337]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0245, 0.0247, 0.0244],\n",
      "          [0.0245, 0.0248, 0.0248],\n",
      "          [0.0242, 0.0251, 0.0251]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0311, 0.0312, 0.0312],\n",
      "          [0.0306, 0.0315, 0.0316],\n",
      "          [0.0328, 0.0337, 0.0337]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0245, 0.0247, 0.0244],\n",
      "          [0.0245, 0.0248, 0.0248],\n",
      "          [0.0242, 0.0251, 0.0251]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0311, 0.0312, 0.0312],\n",
      "          [0.0306, 0.0315, 0.0316],\n",
      "          [0.0328, 0.0337, 0.0337]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0245, 0.0247, 0.0244],\n",
      "          [0.0245, 0.0248, 0.0248],\n",
      "          [0.0242, 0.0251, 0.0251]]]], grad_fn=<MaxPool2DWithIndicesBackward>)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "output shape:  torch.Size([16, 832, 3, 3])\n",
      "Sequential(\n",
      "  (0): Inception(\n",
      "    (p1_1): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p2_1): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p2_2): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (p3_1): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p3_2): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "    (p4_2): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (1): Inception(\n",
      "    (p1_1): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p2_1): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p2_2): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (p3_1): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p3_2): Conv2d(48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "    (p4_2): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (2): GlobalAvgPool2d()\n",
      ")\n",
      "tensor([[[[0.0008]],\n",
      "\n",
      "         [[0.0000]],\n",
      "\n",
      "         [[0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0156]],\n",
      "\n",
      "         [[0.0000]],\n",
      "\n",
      "         [[0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0008]],\n",
      "\n",
      "         [[0.0000]],\n",
      "\n",
      "         [[0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0156]],\n",
      "\n",
      "         [[0.0000]],\n",
      "\n",
      "         [[0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0008]],\n",
      "\n",
      "         [[0.0000]],\n",
      "\n",
      "         [[0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0156]],\n",
      "\n",
      "         [[0.0000]],\n",
      "\n",
      "         [[0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0008]],\n",
      "\n",
      "         [[0.0000]],\n",
      "\n",
      "         [[0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0156]],\n",
      "\n",
      "         [[0.0000]],\n",
      "\n",
      "         [[0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0008]],\n",
      "\n",
      "         [[0.0000]],\n",
      "\n",
      "         [[0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0156]],\n",
      "\n",
      "         [[0.0000]],\n",
      "\n",
      "         [[0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0008]],\n",
      "\n",
      "         [[0.0000]],\n",
      "\n",
      "         [[0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0156]],\n",
      "\n",
      "         [[0.0000]],\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         [[0.0000]]]], grad_fn=<AvgPool2DBackward>)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "output shape:  torch.Size([16, 1024, 1, 1])\n",
      "FlattenLayer()\n",
      "tensor([[0.0008, 0.0000, 0.0000,  ..., 0.0156, 0.0000, 0.0000],\n",
      "        [0.0008, 0.0000, 0.0000,  ..., 0.0156, 0.0000, 0.0000],\n",
      "        [0.0008, 0.0000, 0.0000,  ..., 0.0156, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0008, 0.0000, 0.0000,  ..., 0.0156, 0.0000, 0.0000],\n",
      "        [0.0008, 0.0000, 0.0000,  ..., 0.0156, 0.0000, 0.0000],\n",
      "        [0.0008, 0.0000, 0.0000,  ..., 0.0156, 0.0000, 0.0000]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "output shape:  torch.Size([16, 1024])\n",
      "Linear(in_features=1024, out_features=10, bias=True)\n",
      "tensor([[-0.0192, -0.0089, -0.0201, -0.0029,  0.0206, -0.0176, -0.0344,  0.0038,\n",
      "         -0.0161,  0.0247],\n",
      "        [-0.0192, -0.0089, -0.0201, -0.0029,  0.0206, -0.0176, -0.0344,  0.0038,\n",
      "         -0.0161,  0.0247],\n",
      "        [-0.0192, -0.0089, -0.0201, -0.0029,  0.0206, -0.0176, -0.0344,  0.0038,\n",
      "         -0.0161,  0.0247],\n",
      "        [-0.0192, -0.0089, -0.0201, -0.0029,  0.0206, -0.0176, -0.0344,  0.0038,\n",
      "         -0.0161,  0.0247],\n",
      "        [-0.0192, -0.0089, -0.0201, -0.0029,  0.0206, -0.0176, -0.0344,  0.0038,\n",
      "         -0.0161,  0.0247],\n",
      "        [-0.0192, -0.0089, -0.0201, -0.0029,  0.0206, -0.0176, -0.0344,  0.0038,\n",
      "         -0.0161,  0.0247],\n",
      "        [-0.0192, -0.0089, -0.0201, -0.0029,  0.0206, -0.0176, -0.0344,  0.0038,\n",
      "         -0.0161,  0.0247],\n",
      "        [-0.0192, -0.0089, -0.0201, -0.0029,  0.0206, -0.0176, -0.0344,  0.0038,\n",
      "         -0.0161,  0.0247],\n",
      "        [-0.0192, -0.0089, -0.0201, -0.0029,  0.0206, -0.0176, -0.0344,  0.0038,\n",
      "         -0.0161,  0.0247],\n",
      "        [-0.0192, -0.0089, -0.0201, -0.0029,  0.0206, -0.0176, -0.0344,  0.0038,\n",
      "         -0.0161,  0.0247],\n",
      "        [-0.0192, -0.0089, -0.0201, -0.0029,  0.0206, -0.0176, -0.0344,  0.0038,\n",
      "         -0.0161,  0.0247],\n",
      "        [-0.0192, -0.0089, -0.0201, -0.0029,  0.0206, -0.0176, -0.0344,  0.0038,\n",
      "         -0.0161,  0.0247],\n",
      "        [-0.0192, -0.0089, -0.0201, -0.0029,  0.0206, -0.0176, -0.0344,  0.0038,\n",
      "         -0.0161,  0.0247],\n",
      "        [-0.0192, -0.0089, -0.0201, -0.0029,  0.0206, -0.0176, -0.0344,  0.0038,\n",
      "         -0.0161,  0.0247],\n",
      "        [-0.0192, -0.0089, -0.0201, -0.0029,  0.0206, -0.0176, -0.0344,  0.0038,\n",
      "         -0.0161,  0.0247],\n",
      "        [-0.0192, -0.0089, -0.0201, -0.0029,  0.0206, -0.0176, -0.0344,  0.0038,\n",
      "         -0.0161,  0.0247]], grad_fn=<AddmmBackward>)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "output shape:  torch.Size([16, 10])\n",
      "After: tensor([[-0.0192, -0.0089, -0.0201, -0.0029,  0.0206, -0.0176, -0.0344,  0.0038,\n",
      "         -0.0161,  0.0247],\n",
      "        [-0.0192, -0.0089, -0.0201, -0.0029,  0.0206, -0.0176, -0.0344,  0.0038,\n",
      "         -0.0161,  0.0247],\n",
      "        [-0.0192, -0.0089, -0.0201, -0.0029,  0.0206, -0.0176, -0.0344,  0.0038,\n",
      "         -0.0161,  0.0247],\n",
      "        [-0.0192, -0.0089, -0.0201, -0.0029,  0.0206, -0.0176, -0.0344,  0.0038,\n",
      "         -0.0161,  0.0247],\n",
      "        [-0.0192, -0.0089, -0.0201, -0.0029,  0.0206, -0.0176, -0.0344,  0.0038,\n",
      "         -0.0161,  0.0247],\n",
      "        [-0.0192, -0.0089, -0.0201, -0.0029,  0.0206, -0.0176, -0.0344,  0.0038,\n",
      "         -0.0161,  0.0247],\n",
      "        [-0.0192, -0.0089, -0.0201, -0.0029,  0.0206, -0.0176, -0.0344,  0.0038,\n",
      "         -0.0161,  0.0247],\n",
      "        [-0.0192, -0.0089, -0.0201, -0.0029,  0.0206, -0.0176, -0.0344,  0.0038,\n",
      "         -0.0161,  0.0247],\n",
      "        [-0.0192, -0.0089, -0.0201, -0.0029,  0.0206, -0.0176, -0.0344,  0.0038,\n",
      "         -0.0161,  0.0247],\n",
      "        [-0.0192, -0.0089, -0.0201, -0.0029,  0.0206, -0.0176, -0.0344,  0.0038,\n",
      "         -0.0161,  0.0247],\n",
      "        [-0.0192, -0.0089, -0.0201, -0.0029,  0.0206, -0.0176, -0.0344,  0.0038,\n",
      "         -0.0161,  0.0247],\n",
      "        [-0.0192, -0.0089, -0.0201, -0.0029,  0.0206, -0.0176, -0.0344,  0.0038,\n",
      "         -0.0161,  0.0247],\n",
      "        [-0.0192, -0.0089, -0.0201, -0.0029,  0.0206, -0.0176, -0.0344,  0.0038,\n",
      "         -0.0161,  0.0247],\n",
      "        [-0.0192, -0.0089, -0.0201, -0.0029,  0.0206, -0.0176, -0.0344,  0.0038,\n",
      "         -0.0161,  0.0247],\n",
      "        [-0.0192, -0.0089, -0.0201, -0.0029,  0.0206, -0.0176, -0.0344,  0.0038,\n",
      "         -0.0161,  0.0247],\n",
      "        [-0.0192, -0.0089, -0.0201, -0.0029,  0.0206, -0.0176, -0.0344,  0.0038,\n",
      "         -0.0161,  0.0247]], grad_fn=<AddmmBackward>)\n",
      "tensor([7, 5, 1, 9, 7, 1, 1, 1, 1, 7, 1, 3, 3, 5, 4, 5])\n",
      "tensor(2.2992, grad_fn=<NllLossBackward>)\n",
      "net: Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    (0): Inception(\n",
      "      (p1_1): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception(\n",
      "      (p1_1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(32, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (3): Sequential(\n",
      "    (0): Inception(\n",
      "      (p1_1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(16, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception(\n",
      "      (p1_1): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): Inception(\n",
      "      (p1_1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (3): Inception(\n",
      "      (p1_1): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (4): Inception(\n",
      "      (p1_1): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (4): Sequential(\n",
      "    (0): Inception(\n",
      "      (p1_1): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Inception(\n",
      "      (p1_1): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): GlobalAvgPool2d()\n",
      "  )\n",
      "  (5): FlattenLayer()\n",
      "  (6): Linear(in_features=1024, out_features=10, bias=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ")\n",
      "training on cuda\n",
      "batch_size 16\n",
      "optimizer Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n",
      "num_epochs 5\n",
      "epoch 1, loss 0.1441, train acc 0.109, test acc 0.100, time 96.4 sec\n",
      "epoch 2, loss 0.1440, train acc 0.094, test acc 0.100, time 96.6 sec\n",
      "epoch 3, loss 0.1440, train acc 0.097, test acc 0.100, time 96.5 sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-790ca5886c3a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"net:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m \u001b[0mtrain_ch5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-63-6eae5cc26fb0>\u001b[0m in \u001b[0;36mtrain_ch5\u001b[1;34m(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs, lr)\u001b[0m\n\u001b[0;32m     47\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\n\u001b[0;32m     51\u001b[0m               \u001b[1;34m'time %.1f sec'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-63-6eae5cc26fb0>\u001b[0m in \u001b[0;36mevaluate_accuracy\u001b[1;34m(data_iter, net, device)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_iter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;31m# If device is the GPU, copy the data to the GPU.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "                   nn.ReLU(),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "b2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1),\n",
    "                   nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "b3 = nn.Sequential(Inception(192, 64, (96, 128), (16, 32), 32),\n",
    "                   Inception(256, 128, (128, 192), (32, 96), 64),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "b4 = nn.Sequential(Inception(480, 192, (96, 208), (16, 48), 64),\n",
    "                   Inception(512, 160, (112, 224), (24, 64), 64),\n",
    "                   Inception(512, 128, (128, 256), (24, 64), 64),\n",
    "                   Inception(512, 112, (144, 288), (32, 64), 64),\n",
    "                   Inception(528, 256, (160, 320), (32, 128), 128),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "b5 = nn.Sequential(Inception(832, 256, (160, 320), (32, 128), 128),\n",
    "                   Inception(832, 384, (192, 384), (48, 128), 128),\n",
    "                   GlobalAvgPool2d())\n",
    "\n",
    "net = nn.Sequential(b1, b2, b3, b4, b5, FlattenLayer(), nn.Linear(1024, 10))\n",
    "\n",
    "# Test\n",
    "#batchsize=128\n",
    "batch_size = 16\n",
    "\n",
    "X = torch.rand(batch_size, 1, 96, 96)\n",
    "\n",
    "print(\"Before:\", X)\n",
    "print(\"\\n\\n\\n\\n\")\n",
    "for blk in net.children(): \n",
    "    print(blk)\n",
    "    X = blk(X)\n",
    "    print(X)\n",
    "    print(\"\\n\\n\\n\\n\")\n",
    "    print('output shape: ', X.shape)\n",
    "\n",
    "print(\"After:\", X)\n",
    "print(Y)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "print(loss(X, Y))\n",
    "\n",
    "# 如出现“out of memory”的报错信息，可减小batch_size或resize\n",
    "#train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=96)\n",
    "\n",
    "lr, num_epochs = 0.001, 5\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "print(\"net:\", net)\n",
    "train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
